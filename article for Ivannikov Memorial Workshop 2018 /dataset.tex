\subsection{Описание данных}

Датасет представляет собой набор документов в виде изображений в формате JPEG, скачанный с сайта zakupki.gov.ru \cite{zakupki}. Набор данных доступен для изучения \cite{data}. 

Анализируемые документы являются сканированными копиями страниц текстов государственных закупок. Каждое изображение будем считать отдельным документом. Из рассмотрения удалены документы, содержащие изображения и таблицы.

Данный корпус имеет ряд специфических особенностей. Текст расположен в одной колонке, не выделен цветом, шрифт не меняется (меняется только его начертание или размер). Большая часть всех текстов написана на русском языке, редко встречаются латинские буквы. Так как содержимое документов представляет собой в основном договоры предприятий, в текстах встречается большое количество элементов списков (нумерованных и маркированных), зачастую списки имеют очень глубокий уровень вложенности (четвертый, пятый). Заголовков относительно немного, они могут быть пронумерованы и также иметь глубокий уровень вложенности, поэтому их можно спутать с элементами списков.

Поскольку сканированная копия может быть сделана с любой страницы документа, а не только первой, на некоторых страницах (которые мы считаем отдельным документом) могут отсутствовать заголовки или элементы списков.

Первоначально набор данных состоял из 5000 изображений, однако на большей части этих изображений присутствовали таблицы, рисунки, рамки и прочие нетекстовые элементы, которые не рассматриваются в данной работе. Поэтому в итоговый набор вошли только 600 изображений, удовлетворяющие необходимым требованиям.



\subsection{Разметка данных}
Для создания обучающего набора данных часто используют ручную разметку -- предлагают выполнить задачу классификации человеку-аннотатору. 

В книге \cite{pustejovsky2012natural} предлагается выполнять разметку обучающего корпуса в следующем порядке:


\begin{enumerate}
    \item Спецификация задания -- формальное определение задания и формата данных, используемое ПО и так далее. 
    \item \label{labelingPipeline2} Составление Манифеста -- инструкции для аннотаторов. 
    \item Разметка данных. Непосредственно разметка данных с учётом Манифеста
    \item Измерение согласованности аннотаторов. На этом шаге проверяется то, что размечающие понимают задание одинаково. Если это не так, то производится возврат к шагу \ref{labelingPipeline2}
    \item Вынесение решения по аннотациям -- если каждый пример размечался более чем 1 анотатором, возникает необходимость объединить их результаты. Мы пропустили этот шаг, так как каждый документ размечался одним аннотатором. 
\end{enumerate}
    Опишем эти шаги подробнее применительно к нашей задаче. 
    
    \subsubsection{Спецификация задания}
        Мы поставили нашу задачу как многоклассовую классификацию строк. Аннотаторам последовательно показывались изображения сканированного документа, одна из строк которого обведена в красную рамку. Аннотатору было необходимо отнести текст в рамке к одному из наперёд заданных классов. В нашей задаче выполнялась классификация на следующие классы: 
        \begin{itemize}
            \item Заголовок;
            \item Элемент списка;
            \item Простой текст;
            \item Другое (не текст). 
        \end{itemize}
        Таким образом, аннотатору ставилась задача классификации изображения. Для выполнения этого задания использовалась система собственной разработки \cite{labeler}. После разметки данные сохранялись в формате JSON, формат описан в Приложении.
        %TODO вставить пример
        
    \subsubsection{Манифест}
        В предыдущей секции мы определили задание для разметки как классификацию изображения на один из 
        нескольких классов. Теперь необходимо определить, чем должны руководствоваться аннотаторы, относя 
        изображение к тому или иному классу, в этом им помогает \textit{манифест} или инструкция для разметки.
        
        Как правило, невозможно полностью формально описать правила классификации (в противном случае нам нет необходимости использовать машинное обучение). 
        Поэтому в манифесте допустимо использование нестрого определённых понятий  и правил (например: \textit{жирный текст, выравнивание по центру, изображение синей печати}). При этом важно, чтобы все аннотаторы понимали задание одинаково. Для того, чтобы убедиться в этом, вычисляется согласованность. 
        
    \subsubsection{Согласованность}
        Для проверки одинакового и правильного понимания задания аннотаторами необходимо измерить их согласованность:
        \begin{enumerate}
            \item Предложить нескольким аннотаторам независимо выполнить разметку одного и того же множества заданий. 
            \item Вычислить специальную статистику, показывающую насколько согласована разметка. 
            \item В случае низкой согласованности рекомендуется разобрать спорные ситуации и обновить манифест,
            лучше прописав правила для спорных ситуаций и добавив примеров. 
        \end{enumerate}
        Хороший обзор о методах вычисления согласованности можно найти в статьях
        \cite{artstein2008inter} и \cite{bayerl2011determines}.
        Для проверки правильности разметки была посчитана специальная статистика Cohen's kappa, принимающая значения $\leq 1$. Чем ближе $\kappa$ к 1, тем выше согласованность. После разметки десяти документов (407 строк) двумя аннотаторами значение статистики $\kappa$ оказалось равным 0.975, что считается высоким уровнем согласованности. 
        
        После чего было решено размечать остальной корпус документов. В результате было размечено 600 документов (21350 строк) и отдельные JSON файлы были объединены в один (рис. \ref{fig:label}).
        
        Стоит отметить, что высокая согласованность ещё не означает, что задание выполнено "правильно".
        Так, если все аннотаторы будут всегда относить каждое изображение к классу \textit{"Простой текст"}, не обращая внимания на признаки и манифест, то 
        $\kappa$ будет равна 1, но вряд ли это можно назвать правильной разметкой. Такая проблема актуальна при
        использовании краудсорсинга. Обзор методов краудсорсинга можно найти в статье \cite{gilyzevTurdakov2018}. 