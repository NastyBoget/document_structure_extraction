\documentclass{ProcISPRAS}

% Page geometry. Nearly A5, but not exactly
\usepackage[papersize={14.86cm,21cm},
            left=1.5cm, % 1.4cm
            right=1cm, % 1.5cm
            top=0.8cm, % 0.5cm
            bottom=1cm, % 1.5cm
            includehead,
            headheight=8pt,
            heightrounded,
            headsep=6pt, % 0.4cm
            includefoot,
            footskip=16pt, % I was told that this value should be 9pt. In printed copies of proceedings it is approximately 16pt. Change on your own risk.
]{geometry}

\addbibresource{bibliography.bib}

\usepackage{url}
\usepackage{tikz}
\usepackage{booktabs}
\usepackage{listings}
\usetikzlibrary{positioning}
\usepackage{algorithmicx}
\usepackage{algpseudocode}

\makeatletter
\newenvironment{restoretext}%
    {\@parboxrestore%
     \begin{adjustwidth}{}{\leftmargin}%
    }{\end{adjustwidth}}
\makeatother

\volhead{1}
\issuehead{2}
\pageshead{3--4}
\yearhead{2000}

\setcounter{page}{1} % Set first page number

\date{July 2000}

\newauthor
\inst{1, 2}
\authorname{Bogatenkova A.\,O.}{Богатенкова~А.\,О.}
\email{nastyboget@ispras.ru}

\newauthor
\inst{1}
\authorname{Kozlov I.\,S.}{Козлов~И.\,С.}
\email{kozlov-ilya@ispras.ru}

\newauthor
\inst{1}
\authorname{Belyaeva O.\,V.}{Беляева~О.\,В.}
\email{belyaeva@ispras.ru}

\newauthor
\inst{1, 2}
\authorname{Perminov A.\,I.}{Перминов~А.\,И.}
\email{perminov@ispras.ru}


\affil[1]{Ivannikov Institute for System Programming of the RAS,\\25, Alexander Solzhenitsyn Str., Moscow, 109004, Russia}{Институт системного программирования им. В.П. Иванникова РАН,\\109004, Россия, г. Москва, ул. А. Солженицына, д. 25}

\affil[2]{Lomonosov Moscow State University,\\GSP-1, Leninskie Gory, Moscow, 119991, Russian Federation}{Московский государственный университет имени М.В. Ломоносова,\\119991, Россия, Москва, Ленинские горы, д. 1.}

\title{Logical structure extraction from scanned documents}{Извлечение логической структуры из сканированных документов}

\doi{10.15514/ISPRAS-2000-1(2)-33}
\keywords{machine learning; document structure; natural language processing.}{машинное обучение; структура документа; обработка естественного языка.}

\abstract{% why not write it in English?
There are many pdf-documents without a text layer. Understanding the information in such documents may be useful for their analysis, e. g. for the effective search within documents. This paper describes existing solutions of the structure extraction problem. Generally only headers are identified and classified. A key contribution of our research is extracting both headers and list items from documents. We also made available dataset of documents, which includes bounding boxes and labels for each document line; evaluated the effectiveness of our approach using this dataset and described the possible future work in the field of document processing. }{Большое количество текстовой информации представлено в виде pdf-документов, у которых может отсутствовать текстовый слой. Зачастую требуется осуществлять быстрый поиск по их содержимому. Знание структуры документов может способствовать более эффективному их анализу.
В статье рассмотрены существующие решения задачи извлечения структуры документа в виде иерархии заголовков, а также предложен другой метод решения данной задачи. Данный метод позволяет отличать от остальных строк документа не только заголовки, но и элементы списков. Кроме того, размечен и доступен для изучения корпус документов, проведена экспериментальная проверка реализованного метода на данном корпусе и описаны возможности для дальнейшей работы и исследований.}

\begin{document}

\makedoi

\maketitleen

\newpage

\maketitleru

\section{Введение}

Как правило, документы имеют логическую структуру и содержат название, разбиение на главы, подглавы и т. д., нумерованные и маркированные списки. Выделение такой структуры документа может помочь при решении задач автоматизированного анализа документов, а также при поиске по документам.

Применяется множество разнообразных подходов \cite{fintoc19daniel, fintoc19tian, deep}, которые позволяют выделять в тексте заголовки и распознавать логическую структуру документов. Однако данные подходы подразумевают работу с ограниченным количеством уровней вложенности и не принимают во внимание элементы списков. В данной статье описан метод извлечения структуры документа в виде заголовков, элементов списков и текстовых строк. Каждая строка документа относится к одному из этих трех типов на основе определённых признаков. Для выделения таких признаков может быть необходима метаинформация, такая как размер и тип шрифта, отступы, междустрочные интервалы и т. д. Поэтому извлечение логической структуры логично делать на этапе анализа сканированных документов.

Ограничим класс рассматриваемых документов сканированными документами без текстового слоя. Будем считать, что в документах не содержатся изображения и таблицы.

Статья организована следующим образом:
глава 2 содержит обзор различных подходов, с помощью которых решается задача выделения структуры документа; в главе 3 раскрывается процесс составления обучающего набора данных, в частности описывается набор документов, используемый при реализации и проверке метода и манифест для разметки данных; в главе 4 рассматривается реализованный метод; в главе 5 показаны результаты экспериментальной проверки метода, сравнение различных методов машинного обучения, анализ ошибок и анализ важности признаков, а в главе 6 представлены краткие выводы и предлагаются возможности для дальнейшей работы и исследований.

\section{Обзор аналогичных работ}

По извлечению структуры из документов существуют несколько подходов:
\begin{itemize}
\item на основе оглавления;
\item на основе правил;
\item на основе машинного обучения.
\end{itemize}

\subsection{Извлечение структуры из документов на основе оглавления и правил}

По анализу документов проводится очень много соревнований ICDAR, например \cite{icdar13, icdar17comp, icdar17}. В одном из таких соревнований \cite{icdar13} производилось извлечение структуры из книг, содержимое которых было получено с помощью оптического распознавания символов. Структура книг в виде разбиения на страницы, параграфы, главы извлекалась с использованием оглавления, которое присутствовало в большинстве книг. 

В 2019 году проводились соревнования FinTOC \cite{fintoc19comp}, где из финансовых документов извлекалась структура в виде иерархии уровней заголовков документов. Максимальная глубина уровней равна пяти. Одна из команд-участниц \cite{fintoc19daniel} извлекала необходимую структуру используя оглавление документов, а также систему правил, которые применялись для определения иерархии заголовков.
Сначала идентифицировались страницы, содержащие текст оглавления, затем в документе находились страницы, соответствующие заголовкам, указанным в оглавлении. 
Последним шагом являлось выделение иерархии найденных заголовков, основанное на применении правил: анализировались такие признаки, как междустрочный интервал, отступ, шрифт, символы нумерации.
Использованный подход позволил получить достаточно высокую точность, но низкую полноту, так как некоторые оглавления документов были неполными.

Извлечение структуры документов на основе оглавления имеет ряд недостатков. Во-первых, невозможно обрабатывать документы, в которых нет оглавления. Во-вторых, при использовании этого метода в структуру документа не будут включаться заголовки, которые не вошли в оглавление, например заголовки более низкого уровня. В-третьих, данный метод не позволяет извлекать элементы маркированных и нумерованных списков, которые не включаются в оглавление документа.

\subsection{Извлечение структуры из документов на основе машинного обучения}

В соревнованиях \cite{fintoc19comp} кроме извлечения иерархической структуры документов решалась задача определения, является ли конкретный блок документа заголовком. Командам был дан набор pdf-документов, xml-файлов с выделенными блоками документов, а так же набор признаков для каждого блока: является ли шрифт блока жирным, курсивом, состоит ли текст из заглавных букв, начинается с заглавной буквы или с нумерации. Кроме данных признаков, каждая из команд использовала различные дополнительные морфологические, семантические, лингвистические признаки. На основе этих признаков обучались различные классификаторы: SVM, MNB, Extra Tree, Decision Tree, Gradient Boosting. Для оценки результатов использовалась F1-мера, максимальный score в соревновании -- 0,982.

Победители соревнования \cite{fintoc19tian} создали новый датасет для обучения с помощью аугментации данных, перевели новые сгенерированные текстовые блоки в векторное представление, а затем использовали рекуррентные нейронные сети LSTM и BiLSTM для решения задачи классификации. Процесс аугментации показан на рис. \ref{fig:augmentation}.

\begin{figure}[ht]
    \center{\includegraphics[width=0.5\textwidth]{pics/augmentation.png}}
    \captionisp{Аугментация данных для LSTM и BiLSTM}{Data augmentation for LSTM and BiLSTM}
    \label{fig:augmentation}
\end{figure}

Для того, чтобы классифицировать строки документа, логично использовать такие признаки, как жирность шрифта, отступы, высоту текста и т. д. Эти признаки сильно отличаются друг от друга диапазонами значений, поэтому нейронные сети LSTM и BiLSTM не подходят для решения данной задачи. Кроме того, описанный подход применялся для определения заголовков и не распространялся на элементы списков.

В статье \cite{deep} 2017 года структура документа извлекалась с использованием методов машинного обучения, включая глубокое обучение. Цель данной работы -- автоматически идентифицировать и классифицировать различные секции документов и понять их смысл в рамках документа (назначить семантическую метку).

\begin{figure}[ht]
    \center{\includegraphics[width=0.5\textwidth]{pics/classifier.png}}
    \captionisp{Вход и выход классификатора заголовков}{Input and output of the section classifier}
    \label{fig:classifier}
\end{figure}

Классификатор (рис. \ref{fig:classifier}), который был использован при решении задачи, состоит из нескольких частей. Сначала строки документа подаются на вход классификатору (классификатор строк), который определяет, является ли строка заголовоком, затем строки-заголовки классифицируются точнее другими классификаторами (классификаторы секций). В этом решении структура документа имела вложенность 3, то есть предполагалось выделение секций, подсекций, подподсекций.
Кроме того, в данной работе был размечен датасет, на котором происходило обучение модели. Метрика качества - F1-мера, при идентификации заголовков итоговый score -- 0,96; при классификации секций средний F1-score -- 0,81.

Данный подход ограничивает число уровней вложенности извлекаемой структуры и так же не позволяет извлекать элементы списков.

\section{Набор данных и манифест}

\subsection{Описание данных}

Датасет представляет собой набор документов в виде изображений в формате JPEG, скачанный из интернета. Набор данных доступен для изучения \cite{data}. Документы являются сканированными копиями страниц текстов договоров различных предприятий (СТО, РД ЭО и др.). Каждое изображение будем считать отдельным документом.

Данный корпус имеет ряд специфических особенностей. Документы не содержат таблиц и рисунков (как было указано в ведении), текст расположен строго по-горизонтали, не выделен цветом, шрифт не меняется (меняется только его начертание или размер). Большая часть всех текстов написана на русском языке, редко встречаются латинские буквы. Так как содержимое документов представляет собой в основном договоры предприятий, в текстах встречается большое количество элементов списков (нумерованных и маркированных), зачастую списки имеют очень глубокий уровень вложенности (четвертый, пятый). Заголовков относительно немного, они могут быть пронумерованы и также иметь глубокий уровень вложенности, поэтому их можно спутать с элементами списков.

Поскольку сканированная копия может быть сделана с любой страницы документа, а не только первой, на некоторых страницах (которые мы считаем отдельным документом) могут отсутствовать заголовки или элементы списков.

Первоначально набор данных состоял из 5000 изображений, однако на большей части этих изображений присутствовали таблицы, рисунки, рамки и прочие нетекстовые элементы, которые не рассматриваются в данной работе. Поэтому в итоговый набор вошли только 600 изображений, удовлетворяющие необходимым требованиям.

\subsection{Манифест}

Для разметки документов формализуем задачу классификации. Выделяются следующие типы строк: заголовок, элемент списка, текст.

\begin{enumerate}
	\item Заголовок -- это название главы, секции, подглавы, параграфа. Строка помечается заголовком, если:
	\begin{itemize}
		\item текст визуально (полностью) выделяется жирностью (рис. \ref{fig:1});
		
		\begin{figure}[t]
		    \frame{\includegraphics[width=1.0\textwidth]{manifest/1.png}}
		    \captionisp{Пример заголовка №1}{Header example №1}
		    \label{fig:1}
		\end{figure}
		
		\item текст полностью выделяется шрифтом (курсив, подчеркнутый, другой шрифт, другой размер шрифта) (рис. \ref{fig:2});
		
		\begin{figure}[t]
		    \frame{\includegraphics[width=1.0\textwidth]{manifest/2.png}}
		    \captionisp{Пример заголовка №2}{Header example №2}
		    \label{fig:2}
		\end{figure}
		
		при этом если текст строки выделен шрифтом частично, то заголовком это не считается;
		
		\item текст выделяется отступом (расположен по центру) (рис. \ref{fig:3});
		
		\begin{figure}[t]
		    \frame{\includegraphics[width=1.0\textwidth]{manifest/3.png}}
		    \captionisp{Пример заголовка №3}{Header example №3}
		    \label{fig:3}
		\end{figure}
		
		\item если заголовок занимает несколько строк, остальные строки тоже относятся к типу «заголовок».
	\end{itemize}
	
	\item Элемент списка - это начало нумерованного или маркированного списка. Строка помечается как элемент списка, если:
	\begin{itemize}
		\item строка наряду с несколькими другими строками пронумерована («1. 1) а) 1.1» и т. д. в начале строки) или выделена некоторым маркером (точка, тире и т. д.);
		
		\item если элемент списка визуально занимает несколько строк, все строки кроме первой помечаются как текст. Также к списку не относятся строки, помеченные как заголовок (выделенные шрифтом, жирностью и т. д.).
		
		На рис. \ref{fig:4} как элемент списка будут помечены только две строки, остальные помечаются как текст.
		
		\begin{figure}[t]
		    \frame{\includegraphics[width=1.0\textwidth]{manifest/4.png}}
		    \captionisp{Пример элементов списка}{List example}
		    \label{fig:4}
		\end{figure}
		
	\end{itemize}
	
	\item Текстовые строки -- это все остальные строки, содержащие текст документа.
	\item Other -- при разметке могут попадаться выделенные области, не содержащие текста, такие области помечаются как «Other».
	
\end{enumerate}

\subsection{Разметка данных}

Документы были размечены с использованием специальной системы, разработанной в ИСП РАН \cite{labeler}. Процес разметки проходил следующим образом: в каждом документе последовательно обводились в рамки текстовые строки, которым аннотатор присваивал метку одного из классов. Данные рамки и текст каждой строки распознавались с помощью программы Tesseract \cite{tesseract}.  Результатом разметки стал набор JSON файлов, каждый из которых содержит название документа, размеры изображения и список текстовых строк. Для каждой строки указаны координаты заключающей её рамки (bounding box) и метка принадлежности строки к одному из описанных классов.

\begin{figure}[t]
    \centering
    \begin{lstlisting}[language=Python,frame=none,basicstyle=\ttfamily]
    [
        {
        "name": name of the first document,
        "width": image width (pixels),
        "height": image height,
        "entities": [
            {
                "label": first line label,
                # bounding box for the first line
                "x": first line left indent,
                "y": first line top indent,
                "width": first line width,
                "height": first line height,
                "text": first line text
            }, ...
        }, ...
    ]
    \end{lstlisting}
    \captionisp{Результат разметки}{Labeling result}
    \label{fig:label}
\end{figure}

Для проверки правильности разметки была посчитана специальная статистика Cohen's kappa. После разметки десяти документов двумя аннотаторами значение статистики $\kappa$ оказалось равным 0.975 (чем ближе значение $\kappa$ к единице, тем больший уровень согласия достигнут между аннотаторами), после чего было решено размечать остальной корпус документов. В результате было размечено 600 документов и отдельные JSON файлы были объединены в один (рис. \ref{fig:label}).

\section{Описание решения}

\subsection{Выделение признаков}

Среди признаков, характеризующих строки документа, можно выделить следующие группы:

\begin{itemize}

  \item Признаки, основанные на регулярных выражениях.

  Данная группа признаков основывается на анализе начала и конца каждой строки. Такие признаки очень важны для выявления элементов списков различных типов, а также могут сигнализировать о конце заголовка или начале списка.

  Регулярные выражения позволяют выделить следующие признаки:
  \begin{itemize}

    \item[--] начинается ли строка с цифры или буквы со скобкой или точкой (также анализируются иерархические выражения вида 1.1.1);
    \item[--] начинается ли строка с тире (и других символов, характерных для маркированного списка);
    \item[--] состоит ли строка целиком из заглавных букв (характерно для некоторых заголовков);
    \item[--] начинается ли строка с заглавной (строчной) буквы;
    \item[--] начинается ли строка с конкретных слов типа «Раздел», «Секция», «Глава» и т. д.;
    \item[--] оканчивается ли строка символами вида «. , ; :»;
    \item[--] оканчивается ли строка строчной буквой.

  \end{itemize}

  \item Текстовые признаки.

  Данная группа признаков связана с подсчетом некоторых строковых характеристик, а именно:

  \begin{itemize}

    \item[--] количество букв в первом и втором словах строки;
    \item[--] количество слов в строке (строка разбивается на слова по пробелам);
    \item[--] количество символов в строке (длина строки).

  \end{itemize}

  \item Визуальные признаки.

  Данная группа признаков связана с графическим представлением текста в документе. То есть при анализе строки рассматривается не ее текст, а следующие признаки:

  \begin{itemize}

    \item[--] отступ от левого края страницы;
    \item[--] высота текста строки (точнее высота ограничивающей ее рамки);
    \item[--] отступ от верхнего края страницы;
    \item[--] жирность шрифта различных уровней.

  \end{itemize}

\end{itemize}

\subsection{Описание реализованного метода}

Первым шагом в решении задачи является составление вектора признаков для каждой строки документа. JSON файл, полученный в результате разметки, содержит текст и координаты рамок строк. С помощью выделенной текстовой информации, содержащейся в файле, извлекаются признаки первых двух групп. Для визуальных признаков используется информация из координат рамок (для отступов и высоты). В определении жирности шрифта используется само изображение документа (имя документа также прописано в файле с размеченными данными) и координаты рамок.

Рассмотрим более подробно способ определения жирности шрифта. Для этого использовались морфологические операции Dilation и Erosion из библиотеки OpenCV. Они предполагают применение свертки к изображению с некоторым ядром. Среди пикселей изображения, которые перекрываются ядром, в случае операции dilate вычисляется максимальное значение цвета пикселей, а в случае erode - минимальное. 

При работе с текстом в качестве исходного изображения используется bounding box конкретной строки. При применении к изображению операции dilate увеличивается размер светлых областей, поэтому шрифт становится менее жирным (а может и вовсе пропасть). При применении операции erode наоборот увеличивается размер тёмных областей (в нашем случае шрифт становится более жирным). Таким образом, применяя последовательно сначала операцию dilate, а затем erode, можно добиться исчезновения текста, написанного нежирным шрифтом, более жирный шрифт останется практически без изменений. Далее можно вычислить средний цвет измененного изображения (bounding box-а), значение которого является искомым признаком.  

В зависимости от размера ядра свертки можно варьировать размер тех регионов изображения, на которых вычисляется максимум или минимум, а значит можно определять жирность шрифта различных уровней. В данной работе размер ядра свертки для функций erode и dilate варьировался от 2 до 7 включительно.

Кроме того, к признакам, перечисленным выше, для каждой строки были добавлены аналогичные признаки четырех предыдущих и следующих строк. Это нужно для анализа продолжения блока строк конкретного типа.

Для строк, которые начинаются с нумерации, определялось, есть ли в документе строка, предшествующая данной с нумерацией, меньшей данной на единицу.

И, наконец, для каждого документа вычислялся средний отступ от левого края страницы, средняя высота шрифта, средняя длина строки, среднее число слов в строках, среднее значение дли жирности шрифта (ядро свертки 5), среднее число букв в первом слове каждой строки. Данные значения добавлялись к признакам каждой строки документа.

Таким образом, каждый документ представлен набором векторов признаков для строк, а тренировочные данные являются объединением данных для документов.
Следующим шагом в решении задачи является применение алгоритма машинного обучения, который на основе выделенных признаков распределит строки по классам.

\section{Экспериментальная проверка метода}

\subsection{Подбор классификатора}

При решении задачи было опробовано множество методов машинного обучения, для лучших из них проведен анализ результатов. В анализе участвовало 4 классификатора:

\begin{itemize}

  \item алгоритм k ближайших соседей (\href{https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html}{KNeighborsClassifier});
  \item логистическая регрессия (\href{https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html}{LogisticRegression});
  \item градиентный бустинг (\href{https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html}{GradientBoostingClassifier});
  \item экстра-градиентный бустинг (\href{https://xgboost.readthedocs.io/en/latest/}{XGBClassifier}).

\end{itemize}

Множество документов тремя способами было разбито на тренировочное и тестовое множества (разбиение по документам), на каждом разбиении было проведено обучение классификаторов и вычисление F1-score. Усредненные значения F1-score для каждого классификатора указаны в табл. \ref{tab:classifier_comparison}.
\begin{table}[t]
\captionisp{Сравнение классификаторов}{Classifier comparison}
\begin{tabular}{cc}
 \toprule
    \textbf{Классификатор} & \textbf{F1-score} \\
    \midrule
        Nearest Neighbors & 0.89 \\
        Logistic Regression & 0.9 \\
        Gradient Boosting & 0.92 \\
        \bf XGBoost & \bf 0.95 \\
    \bottomrule
    \end{tabular}
    \label{tab:classifier_comparison}
\end{table}

В целом, все рассмотренные классификаторы показали хороший результат, наилучший результат показал XGBClassifier, поэтому было решено выбрать его.

\subsection{Анализ значимости признаков}

В табл. \ref{tab:features_importances} представлены первые 10 признаков с наивысшей значимостью (information gain). Это признаки, которые имеют наибольший вес при вычислении предсказания классификатора.

\begin{table}[ht]
    \captionisp{Значимость признаков}{Features importances}
    \begin{tabular}{p{0.8\textwidth}p{0.1\textwidth}}
    \toprule
    \textbf{Признак} & \textbf{Information gain} \\
    \midrule
        Число символов первого слова в строке & 22089 \\
        Индикатор, является ли строка продолжением списка & 2400 \\
        Жирность шрифта & 2368 \\
        Число слов в строке & 2263 \\
        Отступ от левого края страницы & 1157 \\
        Признак начала строки с выражения вида 1.1.1 (произвольный уровень вложенности, вместо цифр могут быть буквы) & 1519 \\
        Жирность шрифта (менее жирный шрифт) & 811 \\
        Индикатор, заканчивается ли предыдущая строка буквой & 611 \\
        Число букв в начале строки & 361 \\
        Тире в начале строки & 359 \\
    \bottomrule
    \end{tabular}
    \label{tab:features_importances}
\end{table}

С использованием данных о важности признаков, в признаковое пространство были добавлены новые признаки. Например, вместо одного признака, отвечающего за жирность шрифта, была добавлена целая группа признаков, отвечающая за различные уровни жирности шрифта. Для самых важных признаков к вектору признаков каждой строки документа были добавлены усреднённые значения данных признаков по документу. В табл. \ref{tab:features_importances} представлен итоговый список признаков и значения их важности.

\subsection{Результаты}

После настройки параметров XGBClassifier \cite{tuning} ($learning\_rate=0.1$, $n\_estimators=1000$, $max\_depth=7$, $min\_child\_weight=2$,
$gamma=0$, $subsample=1$, $colsample\_bytree=1$, $alpha=0.01$) итоговый F1-score, полученный в результате кросс-валидации (разбиение данных на 3 части) оказался равным 0.98995. 

\subsection{Анализ ошибок}

На рис. \ref{fig:confusion_matrix} показана \href{https://en.wikipedia.org/wiki/Confusion_matrix}{матрица ошибок} для полученного классификатора. По вертикальной оси расположены правильные классы, по горизонтальной - классы, которые предсказал классификатор. В клетках на пересечении расположены значения количества строк, у которых совпали данные классы.

\begin{figure}[ht]
  \center{\includegraphics[width=0.45\textwidth]{pics/conf_matrix_rus.png}}
  \captionisp{Матрица ошибок без нормализации}{Confusion matrix without normalization}
    \label{fig:confusion_matrix}
\end{figure}

На рисунке видно, что 8 строк, относящихся к типу «Список», были проклассифицированы как «Заголовок», 4 строки, напротив, вместо метки «Заголовок» получили метку «Список». Аналогичную статистику можно посмотреть и для других пар классов.

Таким образом, больше всего классификатор путает классы «Заголовок» и «Список». Это можно объяснить тем, что некоторые признаки данных классов очень похожи, например, многие заголовки начинаются с нумерации, а элементы списков имеют большой отступ от левого края страницы.

\section{Выводы}

В данной статье реализован метод выделения логической структуры документа, основанный на классификации строк документа, определяющий в документах заголовки и списки разных уровней вложенности.

Был обработан с помощью программы Tesseract и размечен набор документов, используемый в качестве тренировочных данных. Для эффективной классификации списков и заголовков может помочь извлечение признаков, указанных в табл. \ref{tab:features_importances} и использование XGBClassifier. Итоговый F1-score на кросс-валидации, полученный при настройке параметров классификатора, равен 0.98995. Однако, в силу особенностей датасета классификатор может путать заголовки и элементы списков.

Дальнейшие исследования могут быть направлены на выделение более подробной структуры. Помимо классификации каждой строки можно определять её уровень вложенности по отношению к документу.

% \begin{otherlanguage}{english}
\printbibliography
% \end{otherlanguage}

\end{document}