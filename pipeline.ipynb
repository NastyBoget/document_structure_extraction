{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопросы на будущее\n",
    "\n",
    "Как оценивать вместе с номером уровня заголовка?\n",
    "\n",
    "1) размечалка + манифест +\n",
    "\n",
    "2) признаки на основе предыдущих (следующих) строк ?\n",
    "\n",
    "3) countvectorizer по первому второму словам +\n",
    "\n",
    "4) признак - средний размер баундин бокса +\n",
    "\n",
    "5) gboost +, randomforest (1000 trees) ?\n",
    "\n",
    "6) жирность\n",
    "\n",
    "7) кросс-валидация по группам +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pytesseract\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from functools import cmp_to_key\n",
    "from functools import reduce\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация заголовков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_bbox_size(bboxes):\n",
    "    \"\"\"\n",
    "    bboxes - list [{\"text\": \"\", \"bbox\": []}, {} ...]\n",
    "    returns (mean_height, mean_width)\n",
    "    \"\"\"\n",
    "    heigths = np.sum(list(map(lambda x: x['bbox'][2], bboxes)))\n",
    "    widths = np.sum(list(map(lambda x: x['bbox'][3], bboxes)))\n",
    "    num_bboxes = len(bboxes)\n",
    "    \n",
    "    return (heigths / num_bboxes, widths / num_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddImgFeatures:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X - [{\"name\": \"doc_name\", \"entities\": [{\"text\": \"\", \"bbox\": []}]}]\n",
    "        returns features [normalized bbox sizes, normalized mean size of bbox]\n",
    "        [normalized left, normalized top,\n",
    "        normalized width, normalized height,\n",
    "        mean height, mean width]\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        for doc in X:\n",
    "            doc_name = doc['name']\n",
    "            doc_info = doc['entities']\n",
    "            mean_heigth, mean_width = mean_bbox_size(doc_info)\n",
    "            img = cv2.imread('docs/' + doc_name)\n",
    "            heigth = img.shape[0]\n",
    "            width = img.shape[1]\n",
    "            for line_info in doc_info:\n",
    "                features.append([line_info['bbox'][0] / width,\n",
    "                                line_info['bbox'][1] / heigth,\n",
    "                                line_info['bbox'][2] / width,\n",
    "                                line_info['bbox'][3] / heigth,\n",
    "                                mean_heigth, mean_width])\n",
    "        return features\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_LIST = re.compile(r'\\d+(\\.\\d+)*\\D')\n",
    "RE_HEADER = re.compile(r'Раздел|Подраздел|Глава|Параграф|Секция|Часть|Статья')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddRegFeatures:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X - [{\"name\": \"doc_name\", \"entities\": [{\"text\": \"\", \"bbox\": []}]}]\n",
    "        returns features: [list, header] 1 - yes, 0 - no\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        for doc in X:\n",
    "            doc_info = doc['entities']\n",
    "            for line_info in doc_info:\n",
    "                line = line_info['text']\n",
    "                match = RE_LIST.search(line)\n",
    "                if match:\n",
    "                    if match.start() == 0:\n",
    "                        features.append([1, 0])\n",
    "                        continue\n",
    "                match = RE_HEADER.search(line)\n",
    "                if match:\n",
    "                    if match.start() == 0:\n",
    "                        features.append([0, 1])\n",
    "                        continue\n",
    "                features.append([0, 0])\n",
    "        return features\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class string2features:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self):\n",
    "        pass\n",
    "\n",
    "    def predict(self):\n",
    "        pass\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        return self.transform(X)\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X - [{\"name\": \"doc_name\", \"entities\": [{\"text\": \"\", \"bbox\": []}]}]\n",
    "        returns: list of first 1-2 words of each line\n",
    "        \"\"\"\n",
    "        first_words = []\n",
    "        for doc in X:\n",
    "            doc_info = doc['entities']\n",
    "            for line_info in doc_info:\n",
    "                line_words = line_info['text'].split()\n",
    "                if len(line_words) > 1:\n",
    "                    first_words.append(line_words[0] + ' ' + line_words[1])\n",
    "                elif line_words:\n",
    "                    first_words.append(line_words[0])\n",
    "                else:\n",
    "                    first_words.append('')\n",
    "        return first_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://neurohive.io/ru/osnovy-data-science/gradientyj-busting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.json\", \"r\") as read_file:\n",
    "    docs = json.load(read_file)\n",
    "    y = []\n",
    "    for doc in docs:\n",
    "        elem = [line['label'] for line in doc['entities']]\n",
    "        y.append(elem)\n",
    "    X = []\n",
    "    for doc in docs:\n",
    "        elem = {}\n",
    "        elem['name'] = doc['name']\n",
    "        elem['entities'] = [{'text': line_info['text'], \n",
    "                        'bbox': [line_info['x'], line_info['y'],\n",
    "                                line_info['width'], line_info['height']]}\n",
    "                      for line_info in doc['entities']]\n",
    "        X.append(elem)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7641779581021316, 0.7624716061411333, 0.6801341912201196]\n",
      "0.7355945851544615\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(FeatureUnion([('aif', AddImgFeatures()),\n",
    "                                  ('af', AddRegFeatures()),\n",
    "                                  ('cv', make_pipeline(\n",
    "                                      string2features(),\n",
    "                                      CountVectorizer(token_pattern=r'(?u)\\b\\w+\\b')))]), \n",
    "                     GradientBoostingClassifier())\n",
    "\n",
    "scores = []\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train = reduce(lambda x1, x2: x1 + x2, y[train_index])\n",
    "    y_test = reduce(lambda x1, x2: x1 + x2, y[test_index])\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression с 10 примерами 0.3825286683816205"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoostingClassifier с 10 примерами 0.7602626622815247\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoostingClassifier с 32 примерами на 3 фолдах 0.6904364633429961"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoostingClassifier с 46 примерами на 3 фолдах 0.6863249684821809\n",
    "\n",
    "с 142 примерами 0.7355945851544615"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cohen_kappa_score\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"file_with_labels2.json\", \"r\") as read_file:\n",
    "    labeled_doc = json.load(read_file)\n",
    "with open(\"file_with_labels2_ilya.json\", \"r\") as read_file:\n",
    "    labeled_doc_ilya = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(x, y):\n",
    "    if x['name'] == y['name']:\n",
    "        if x['bbox'][1] < y['bbox'][1]:\n",
    "            return -1\n",
    "        else:\n",
    "            return 1\n",
    "    elif x['name'] < y['name']:\n",
    "        return -1 \n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_doc.sort(key=cmp_to_key(cmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_doc_ilya.sort(key=cmp_to_key(cmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_doc_ilya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = [x[\"label\"] for x in labeled_doc]\n",
    "labels2 = [x[\"label\"] for x in labeled_doc_ilya]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_kappa_score(labels1, labels2, labels=[1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i, elem in enumerate(labeled_doc):\n",
    "    d[(tuple(elem['bbox']), elem['name'])] = [labels1[i], labels2[i]]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in d.items():\n",
    "    if (len(item[1]) == 1) or (len(item[1]) == 2 \n",
    "                               and item[1][0] != item[1][1]):\n",
    "        img = cv2.imread('different_docs/' + item[0][1])\n",
    "        (x, y, w, h) = item[0][0]\n",
    "        cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.imwrite('different_docs/' + item[0][1], img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
