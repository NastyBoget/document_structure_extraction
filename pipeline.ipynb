{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопросы на будущее\n",
    "\n",
    "Насколько сложная структура может быть (насколько сложные и разнообразные документы)? \n",
    "\n",
    "Как оценивать вместе с номером уровня заголовка?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Извлечение текста из pdf\n",
    "https://www.severcart.ru/blog/all/tesseract_ocr_python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2text import pdf2text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация заголовков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "RE_LIST = re.compile(r'\\d+(\\.\\d+)*\\D') # для отдельного типа списка\n",
    "RE_HEADER = re.compile(r'Раздел|Подраздел|Глава|Параграф|Секция|Часть|Статья')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "\n",
    "def mean_bbox_size(img):\n",
    "    \"\"\"\n",
    "    returns (mean_height, mean_width)\n",
    "    \"\"\"\n",
    "    d = pytesseract.image_to_data(img, lang='rus+eng', \n",
    "                                  output_type=pytesseract.Output.DICT)\n",
    "    \n",
    "    box = [0, 0, 0] # heights, widths, num_lines\n",
    "    for i in range(len(d['level'])):\n",
    "        if d['level'][i] == 4:  # bounding box of text line\n",
    "            box[0] += d['height'][i]\n",
    "            box[1] += d['width'][i]\n",
    "            box[2] += 1\n",
    "    return (box[0] / box[2], box[1] / box[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "class AddImgFeatures:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self):\n",
    "        pass\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X - dict {\"text\": \"\", \"bbox\": [], \"name\": \"\"}\n",
    "        computes mean size of bbox\n",
    "        returns features normalized bbox sizes + mean size of bbox\n",
    "        \"\"\"\n",
    "        path = 'docs'\n",
    "        mean_heights = {} # {\"name\": [\"mean_height\", \"mean_width\", \"height\", \"width\"]}\n",
    "        features = []\n",
    "        for elem in X:\n",
    "            if elem['name'] not in mean_heights: \n",
    "                img = cv2.imread(path + '/' + elem['name'])\n",
    "                mean_height, mean_width = mean_bbox_size(img)\n",
    "                mean_heights[elem['name']] = [mean_height / img.shape[0], \n",
    "                                              mean_width / img.shape[1], \n",
    "                                              img.shape[0], img.shape[1]]\n",
    "            h0 = mean_heights[elem['name']][2]\n",
    "            w0 = mean_heights[elem['name']][3]\n",
    "            # normalized left, normalized top?,\n",
    "            # normalized width, normalized height,\n",
    "            # mean height, mean width\n",
    "            features.append([elem['bbox'][0] / w0, #elem['bbox'][1] / h0,\n",
    "                             elem['bbox'][2] / w0, elem['bbox'][3] / h0,\n",
    "                             mean_heights[elem['name']][0], \n",
    "                             mean_heights[elem['name']][1]])\n",
    "        return features\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddFeatures:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self):\n",
    "        pass\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        features 2 columns: 1-list, 2-header\n",
    "        X - dict {\"text\": \"\", \"bbox\": [], \"name\": \"\"}\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        for elem in X:\n",
    "            line = elem['text']\n",
    "            match = RE_LIST.search(line)\n",
    "            if match:\n",
    "                if match.start() == 0:\n",
    "                    features.append([1, 0])\n",
    "                    continue\n",
    "            match = RE_HEADER.search(line)\n",
    "            if match:\n",
    "                if match.start() == 0:\n",
    "                    features.append([0, 1])\n",
    "                    continue\n",
    "            features.append([0, 0])\n",
    "        return features\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class string2features:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self):\n",
    "        pass\n",
    "\n",
    "    def predict(self):\n",
    "        pass\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        return self.transform(X)\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X - список строк\n",
    "        \"\"\"\n",
    "        first_words = []\n",
    "        for elem in X:\n",
    "            line = elem['text']\n",
    "            line_words = line.split()\n",
    "            if len(line_words) > 1:\n",
    "                first_words.append(line_words[0] + ' ' + line_words[1])\n",
    "            elif line_words:\n",
    "                first_words.append(line_words[0])\n",
    "            else:\n",
    "                first_words.append('')\n",
    "        return first_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from string2features import string2features\n",
    "\n",
    "ppl = make_pipeline(FeatureUnion([('aif', AddImgFeatures()), \n",
    "                                  ('af', AddFeatures()),\n",
    "                                  ('cv', make_pipeline(\n",
    "                                      string2features(),\n",
    "                                      CountVectorizer(token_pattern=r'(?u)\\b\\w+\\b')))]), \n",
    "                     LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель:\n",
    "логистическая регрессия, для каждой строки - тип строки + уровень???\n",
    "\n",
    "как работать с уровнем? строка-название + строка-уровень"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"file_train2.json\", \"r\") as read_file:\n",
    "    doc_with_labels = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [doc_with_labels[0]]\n",
    "aif = AddImgFeatures()\n",
    "print(aif.transform(x1))\n",
    "af = AddFeatures()\n",
    "print(af.transform(x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем и сохраняем обученную модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "clf = ppl.fit(X, y)\n",
    "pkl.dump(clf, open(\"model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кросс-валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"file_with_labels2.json\", \"r\") as read_file:\n",
    "    doc_test = json.load(read_file)\n",
    "    y = [x[\"label\"] for x in doc_test]\n",
    "    X = [{\"text\": x[\"text\"], \"bbox\": x[\"bbox\"], \"name\": x[\"name\"]} for x in doc_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([28.79997182, 30.72871709, 26.89271808]),\n",
       " 'score_time': array([16.05080819, 22.01762104, 13.94769192]),\n",
       " 'test_score': array([0.65693608, 0.85328133, 0.77057057])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "clf = make_pipeline(FeatureUnion([('aif', AddImgFeatures()),\n",
    "                                  ('af', AddFeatures()),\n",
    "                                  ('cv', make_pipeline(\n",
    "                                      string2features(),\n",
    "                                      CountVectorizer(token_pattern=r'(?u)\\b\\w+\\b')))]), \n",
    "                     GradientBoostingClassifier())\n",
    "scores = cross_validate(clf, X, y, cv=3, scoring='f1_macro')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "без aif 0.37956220744365304"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c aif 0.37134152944319837"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "с нормализованной aif 0.3825286683816205"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoostingClassifier с нормализованной aif 0.38252866838162050.7602626622815247\n",
    "\n",
    "без aif 0.41892482779902956"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7602626622815247"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "score = np.mean(scores['test_score'])\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) размечалка + манифест +\n",
    "\n",
    "2) признаки на основе предыдущих (следующих) строк ?\n",
    "\n",
    "3) countvectorizer по первому второму словам +\n",
    "\n",
    "4) признак - средний размер баундин бокса +\n",
    "\n",
    "5) gboost +, randomforest (1000 trees) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
