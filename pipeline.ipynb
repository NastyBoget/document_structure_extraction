{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) посмотреть, где ошибается классификатор\n",
    "\n",
    "2) тюнить параметры\n",
    "\n",
    "3) важность признаков +\n",
    "\n",
    "4) переразметить некоторые документы +\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from sklearn.pipeline import make_pipeline, FeatureUnion\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import xgbfir\n",
    "from itertools import product\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_expr = [re.compile(r'\\d+(\\.\\d+)+\\D'), # 1.1.1 1\n",
    "            re.compile(r'\\d+[\\)\\}]'), # 1) 2\n",
    "            re.compile(r'\\w+(\\.\\w+)+\\W'), # 3\n",
    "            re.compile(r'[а-яА-Я\\d]+(\\.[а-яА-Я\\d]+)+\\W'), # b.b.b 4\n",
    "            re.compile(r'[\\wа-яА-Я]\\.\\W'), # b. 5\n",
    "            re.compile(r'[6а-яА-Яa-zA-Z][\\)\\}]'), # б) 6\n",
    "            re.compile(r'\\-|—'), # - 7\n",
    "            re.compile(r'®|\\*'), # * 8\n",
    "            re.compile(r'[a-zа-я]'), # строчная буква в начале 9\n",
    "            re.compile(r'[A-ZА-Я]'),  # заглавная буква в начале 10\n",
    "            re.compile(r'Раздел|Подраздел|Глава|Параграф|Секция|Часть|Статья')] # 11\n",
    "\n",
    "def add_reg_features(line):\n",
    "    features = [0] * len(reg_expr)\n",
    "    i = 0\n",
    "    for expr in reg_expr:\n",
    "        match = expr.search(line)\n",
    "    \n",
    "        if match:\n",
    "            if match.start() == 0:\n",
    "                features[i] = 1\n",
    "        i += 1\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_reg_expr = [re.compile(r'.*\\.'),\n",
    "                re.compile(r'.*;'),\n",
    "                re.compile(r'.*:'),\n",
    "                re.compile(r'.*,'),\n",
    "                re.compile(r'.*[\\wа-яА-Я]')]\n",
    "\n",
    "def add_end_reg_features(line):\n",
    "    features = [0] * len(end_reg_expr)\n",
    "    i = 0\n",
    "    for expr in end_reg_expr:\n",
    "        match = expr.fullmatch(line)\n",
    "        if match:\n",
    "            features[i] = 1\n",
    "        i += 1\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_bbox_size(bboxes):\n",
    "    \"\"\"\n",
    "    bboxes - list [{\"text\": \"\", \"bbox\": []}, {} ...]\n",
    "    returns (mean_height, mean_width)\n",
    "    \"\"\"\n",
    "    lefts = np.sum(list(map(lambda x: x['bbox'][0], bboxes)))\n",
    "    widths = np.sum(list(map(lambda x: x['bbox'][2], bboxes)))\n",
    "    heigths = np.sum(list(map(lambda x: x['bbox'][3], bboxes)))\n",
    "    num_bboxes = len(bboxes)\n",
    "    \n",
    "    return (lefts / num_bboxes, heigths / num_bboxes, widths / num_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more complex font-weight detection\n",
    "\n",
    "def bold_mean_color(bbox, img):\n",
    "    x, y, w, h = bbox\n",
    "    crop_img = img[y:y + h, x:x + w]\n",
    "    kernel = np.ones((5, 5),np.uint8)\n",
    "    dilation = cv2.dilate(crop_img, kernel, iterations = 1)\n",
    "    kernel = np.ones((7, 7),np.uint8)\n",
    "    erosion = cv2.erode(dilation, kernel, iterations = 1)\n",
    "    avg_color_per_row = np.average(erosion, axis=0)\n",
    "    avg_color = np.average(avg_color_per_row, axis=0)\n",
    "    return np.average(avg_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add simple font-weight detection\n",
    "\n",
    "def mean_color(bbox, img):\n",
    "    x, y, w, h = bbox\n",
    "    crop_img = img[y:y + h, x:x + w]\n",
    "    avg_color_per_row = np.average(crop_img, axis=0)\n",
    "    avg_color = np.average(avg_color_per_row, axis=0)\n",
    "    return np.average(avg_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount letters of the first word in line\n",
    "\n",
    "RE_WORD = re.compile(r'[a-zA-Zа-яА-Я]+')\n",
    "\n",
    "def letters_cnt(line):\n",
    "    match = RE_WORD.search(line)\n",
    "\n",
    "    if match:\n",
    "        if match.start() == 0: # word in the beginning of the line\n",
    "            return len(match.group(0))\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class AddImgFeatures:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X - [{\"name\": \"doc_name\", \"entities\": [{\"text\": \"\", \"bbox\": []}]}]\n",
    "        returns features [normalized bbox sizes, normalized mean size of bbox]\n",
    "        [normalized left, normalized top,\n",
    "        normalized width, normalized height,\n",
    "        mean height, mean width]\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        for doc in X:\n",
    "            doc_features = []\n",
    "            doc_name = doc['name']\n",
    "            doc_info = doc['entities']\n",
    "            \n",
    "            sum_avg_colors = 0\n",
    "            sum_line_cnt = 0\n",
    "            \n",
    "            mean_left, mean_heigth, mean_width = mean_bbox_size(doc_info)\n",
    "            img = cv2.imread('docs/' + doc_name)\n",
    "            \n",
    "            avg_color_per_row = np.average(img, axis=0)\n",
    "            avg_color = np.average((np.average(avg_color_per_row, axis=0)))\n",
    "            \n",
    "            heigth = img.shape[0]\n",
    "            width = img.shape[1]\n",
    "            for line_info in doc_info:\n",
    "                line_color = mean_color(line_info['bbox'], img)\n",
    "                bold_line_color = bold_mean_color(line_info['bbox'], img)\n",
    "                line_features = [line_info['bbox'][0] / width,\n",
    "                                line_info['bbox'][1] / heigth,\n",
    "                                line_info['bbox'][2] / width,\n",
    "                                line_info['bbox'][3] / heigth,\n",
    "                                mean_left, mean_heigth, mean_width,\n",
    "                                line_color, bold_line_color, avg_color]\n",
    "                sum_avg_colors += line_color\n",
    "                line_features += add_reg_features(line_info['text'])\n",
    "                line_features += add_end_reg_features(line_info['text'])\n",
    "                \n",
    "                word_cnt = len(line_info['text'].split())\n",
    "                word_letters_cnt = letters_cnt(line_info['text'])\n",
    "                line_cnt = len(line_info['text'])\n",
    "                line_features += [word_letters_cnt, line_cnt, word_cnt]\n",
    "                sum_line_cnt += line_cnt\n",
    "                \n",
    "                doc_features.append(line_features)\n",
    "            mean_line_color = sum_avg_colors / len(doc_info)\n",
    "            mean_line_cnt = sum_line_cnt / len(doc_info)\n",
    "            for line_features in doc_features:\n",
    "                line_features += [mean_line_cnt, mean_line_color]\n",
    "            features.append(doc_features)\n",
    "        return features\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prev_next_features(doc, line_features, num_line):\n",
    "    \"\"\"\n",
    "    doc - list of line_features\n",
    "    line_features - list of features\n",
    "    \"\"\"\n",
    "    add_f = [0] * len(line_features)\n",
    "    extended_doc = [add_f] * 4 + doc + [add_f] * 4\n",
    "    prev_features = reduce(lambda x, y: x + y, \n",
    "                           extended_doc[num_line: num_line + 4])\n",
    "    next_features = reduce(lambda x, y: x + y, \n",
    "                           extended_doc[num_line + 5: num_line + 9])\n",
    "    return line_features + prev_features + next_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddPrevNextFeatures:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X - list of doc_features\n",
    "        doc_features - list of line_features\n",
    "        \n",
    "        for each line 4 previous and 4 next features added\n",
    "        result list of lines features\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        for doc_features in X:\n",
    "            i = 0\n",
    "            for line_features in doc_features:\n",
    "                new_features = add_prev_next_features(doc_features, line_features, i)\n",
    "                i += 1\n",
    "                result.append(new_features)\n",
    "        return np.array(result)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2class = {\n",
    "    \"header\" : 1,\n",
    "    \"list\" : 2,\n",
    "    \"text\" : 3,\n",
    "    \"other\" : 4\n",
    "}\n",
    "\n",
    "with open(\"data.json\", \"r\") as read_file:\n",
    "    docs = json.load(read_file)\n",
    "    y = []\n",
    "    for doc in docs:\n",
    "        elem = [label2class[line['label']] for line in doc['entities']]\n",
    "        y.append(elem)\n",
    "    X = []\n",
    "    for doc in docs:\n",
    "        elem = {}\n",
    "        elem['name'] = doc['name']\n",
    "        elem['entities'] = [{'text': line_info['text'], \n",
    "                        'bbox': [line_info['x'], line_info['y'],\n",
    "                                line_info['width'], line_info['height']]}\n",
    "                      for line_info in doc['entities']]\n",
    "        X.append(elem)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters tuning:\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anastasiabogatenkova/miniconda3/envs/doc-py37/lib/python3.7/site-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c5531a1fba487dbb3685dd327becb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anastasiabogatenkova/miniconda3/envs/doc-py37/lib/python3.7/site-packages/ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c650a15b91864db1a516f4943f73b9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.8889457934491194\n",
      "Pipeline(memory=None,\n",
      "         steps=[('addimgfeatures',\n",
      "                 <__main__.AddImgFeatures object at 0x1a29f6cd90>),\n",
      "                ('addprevnextfeatures',\n",
      "                 <__main__.AddPrevNextFeatures object at 0x1a29f6cd10>),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster=None,\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=0, max_depth=6,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=100,\n",
      "                               n_jobs=4, nthread=4, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method=None,\n",
      "                               validate_parameters=False, verbosity=None))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6ca98ad5c048ca825b46f332e04099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.8922883145245217\n",
      "Pipeline(memory=None,\n",
      "         steps=[('addimgfeatures',\n",
      "                 <__main__.AddImgFeatures object at 0x1a2c793f50>),\n",
      "                ('addprevnextfeatures',\n",
      "                 <__main__.AddPrevNextFeatures object at 0x1a2c793e90>),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster=None,\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_delta_step=0, max_depth=9,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=100,\n",
      "                               n_jobs=4, nthread=4, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method=None,\n",
      "                               validate_parameters=False, verbosity=None))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0938ab73e1a649fd8dcf940050b40e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.9061696651994601\n",
      "Pipeline(memory=None,\n",
      "         steps=[('addimgfeatures',\n",
      "                 <__main__.AddImgFeatures object at 0x10cb55950>),\n",
      "                ('addprevnextfeatures',\n",
      "                 <__main__.AddPrevNextFeatures object at 0x10cb55850>),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster=None,\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=6,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=100,\n",
      "                               n_jobs=4, nthread=4, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method=None,\n",
      "                               validate_parameters=False, verbosity=None))],\n",
      "         verbose=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e40fb788080489d984b6f120bb16d3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.9110389561192539\n",
      "Pipeline(memory=None,\n",
      "         steps=[('addimgfeatures',\n",
      "                 <__main__.AddImgFeatures object at 0x1a2a8472d0>),\n",
      "                ('addprevnextfeatures',\n",
      "                 <__main__.AddPrevNextFeatures object at 0x1a2a847810>),\n",
      "                ('xgbclassifier',\n",
      "                 XGBClassifier(base_score=0.5, booster=None,\n",
      "                               colsample_bylevel=1, colsample_bynode=1,\n",
      "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "                               importance_type='gain',\n",
      "                               interaction_constraints=None, learning_rate=0.1,\n",
      "                               max_delta_step=0, max_depth=9,\n",
      "                               min_child_weight=1, missing=nan,\n",
      "                               monotone_constraints=None, n_estimators=100,\n",
      "                               n_jobs=4, nthread=4, num_parallel_tree=1,\n",
      "                               objective='multi:softprob', random_state=0,\n",
      "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "                               subsample=1, tree_method=None,\n",
      "                               validate_parameters=False, verbosity=None))],\n",
      "         verbose=False)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=None,\n",
       "          steps=[('addimgfeatures',\n",
       "                  <__main__.AddImgFeatures object at 0x1a2a8472d0>),\n",
       "                 ('addprevnextfeatures',\n",
       "                  <__main__.AddPrevNextFeatures object at 0x1a2a847810>),\n",
       "                 ('xgbclassifier',\n",
       "                  XGBClassifier(base_score=0.5, booster=None,\n",
       "                                colsample_bylevel=1, colsample_bynode=1,\n",
       "                                colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                                importance_type='gain',\n",
       "                                interaction_constraints=None, learning_rate=0.1,\n",
       "                                max_delta_step=0, max_depth=9,\n",
       "                                min_child_weight=1, missing=nan,\n",
       "                                monotone_constraints=None, n_estimators=100,\n",
       "                                n_jobs=4, nthread=4, num_parallel_tree=1,\n",
       "                                objective='multi:softprob', random_state=0,\n",
       "                                reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "                                subsample=1, tree_method=None,\n",
       "                                validate_parameters=False, verbosity=None))],\n",
       "          verbose=False), 0.9110389561192539)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = product(\n",
    "    # (800, 1000, 1200), # n_estimators\n",
    "    (0.01, 0.1), # learning_rate\n",
    "    (6, 9), # max_depth\n",
    ")\n",
    "\n",
    "res_score = 0\n",
    "\n",
    "for learning_rate, max_depth in tqdm(list(params)):\n",
    "    clf = make_pipeline(AddImgFeatures(),\n",
    "                    AddPrevNextFeatures(),\n",
    "                    XGBClassifier( \n",
    "                                  learning_rate=learning_rate,\n",
    "                                  max_depth=max_depth, \n",
    "                                  nthread=4))\n",
    "    scores = []\n",
    "    n_folds = 3\n",
    "    kf = KFold(n_splits=n_folds)\n",
    "    for train_index, test_index in tqdm(kf.split(X), total=n_folds):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train = np.array(reduce(lambda x1, x2: x1 + x2, y[train_index]))\n",
    "        y_test = np.array(reduce(lambda x1, x2: x1 + x2, y[test_index]))\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    score = np.mean(scores)\n",
    "    print(score)\n",
    "    print(clf)\n",
    "    if score > res_score:\n",
    "        res_score = score\n",
    "        res_model = clf\n",
    "        \n",
    "res_model, res_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anastasiabogatenkova/miniconda3/envs/doc-py37/lib/python3.7/site-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4b3f5bd2be44d4bde7fbfea798b6fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.9144497329963064, 0.8936818617377597, 0.903432697730674]\n",
      "0.9038547641549134\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(AddImgFeatures(),\n",
    "                    AddPrevNextFeatures(),\n",
    "                    XGBClassifier())\n",
    "\n",
    "scores = []\n",
    "\n",
    "n_folds = 3\n",
    "kf = KFold(n_splits=n_folds)\n",
    "for train_index, test_index in tqdm(kf.split(X), total=n_folds):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train = np.array(reduce(lambda x1, x2: x1 + x2, y[train_index]))\n",
    "    y_test = np.array(reduce(lambda x1, x2: x1 + x2, y[test_index]))\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ analyzing first letters\n",
    "\n",
    "[0.8867675684671439, 0.8416159246088081, 0.8389276076502283]\n",
    "0.8557703669087268\n",
    "\n",
    "+ amount words in each line\n",
    "\n",
    "[0.9171126668036368, 0.8439571218609735, 0.8602771104301121]\n",
    "0.8737822996982407\n",
    "\n",
    "+ mean amount words\n",
    "\n",
    "[0.8866792540310675, 0.833351085001163, 0.8608445425282144]\n",
    "0.860291627186815\n",
    "\n",
    "+ end reg features \n",
    "\n",
    "[0.9200323878813053, 0.8572318771961986, 0.8704681112224602]\n",
    "0.8825774587666547\n",
    "\n",
    "+ more complex font-weight detection\n",
    "\n",
    "[0.9231266489757199, 0.8659729687440885, 0.8969791161008724]\n",
    "0.8953595779402269\n",
    "\n",
    "+ 600 documents\n",
    "\n",
    "[0.9144497329963064, 0.8936818617377597, 0.903432697730674]\n",
    "0.9038547641549134"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature importances https://github.com/limexp/xgbfir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8961636734684715"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor = make_pipeline(AddImgFeatures(),\n",
    "                                  AddPrevNextFeatures())\n",
    "scores = [] # (train_cnt, score)\n",
    "train_num = [500, 450, 400, 350, 300]\n",
    "\n",
    "for train_cnt in train_num:\n",
    "    xgb_cmodel = XGBClassifier()\n",
    "    X, y = X, y = shuffle(X, y, random_state=0)\n",
    "    X_train, X_test = X[:train_cnt], X[train_cnt:]\n",
    "    y_train = np.array(reduce(lambda x1, x2: x1 + x2, y[:train_cnt]))\n",
    "    y_test = np.array(reduce(lambda x1, x2: x1 + x2, y[train_cnt:]))\n",
    "\n",
    "    X_train = feature_extractor.fit_transform(X_train)\n",
    "    X_test = feature_extractor.fit_transform(X_test)\n",
    "\n",
    "    xgb_cmodel.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = xgb_cmodel.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred, average='macro')\n",
    "    print(score)\n",
    "    scores.append(train_cnt, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names(names):\n",
    "    feature_names = names.copy()\n",
    "    for i in range(1, 5):\n",
    "        for name in names:\n",
    "            feature_names.append(str(i) + '_prev_' + name)\n",
    "    for i in range(1, 5):\n",
    "        for name in names:\n",
    "            feature_names.append(str(i) + '_next_' + name)\n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = get_feature_names(['left', 'top', 'wigth', 'height', \n",
    "                'mean_left', 'mean_height', 'mean_width',\n",
    "                'line_color', 'bold_line_color', 'avg_color', 'reg1', 'reg2',\n",
    "                'reg3', 'reg4', 'reg5', 'reg6', 'reg7',\n",
    "                'reg8', 'reg9', 'reg10', 'reg11',\n",
    "                'end_reg1', 'end_reg2', 'end_reg3', 'end_reg4', 'end_reg5',\n",
    "                'word_letters_cnt', 'line_cnt', 'word_cnt', 'mean_line_cnt',\n",
    "                'mean_line_color'])\n",
    "\n",
    "xgbfir.saveXgbFI(xgb_cmodel, feature_names=feature_names, \n",
    "                 OutputXlsxFile='fearures_importances.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_test [{\"name\": \"doc_name\", \"entities\": [{\"text\": \"\", \"bbox\": []}]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[:500], X[500:]\n",
    "\n",
    "d = {}\n",
    "i = 0\n",
    "for doc_info in X_test:\n",
    "    for line_info in doc_info['entities']:\n",
    "        d[(tuple(line_info['bbox']), doc_info['name'], line_info[\"text\"])] = [y_test[i], y_pred[i]]\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anastasiabogatenkova/miniconda3/envs/doc-py37/lib/python3.7/site-packages/ipykernel_launcher.py:21: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f26405f8d184496a3b50883b2cc6c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10кВ рубящего или качающегося типа. Все стальные части разъединителя, в том\n",
      "\n",
      "2.12. Особые условия:\n",
      "\n",
      "2.12.4.\n",
      "\n",
      "2.13. Подрядчик после окончания строительно-монтажных и пусконаладочных работ\n",
      "\n",
      "представляет следующую документацию:\n",
      "\n",
      "2.13.4. Акты освидетельствования скрытых работ;\n",
      "\n",
      "1.6. Особые условия.\n",
      "\n",
      "cook\n",
      "\n",
      "SA\n",
      "\n",
      "3.4. Вывод о достоверности или недостоверности определения сметной стоимости строительства,\n",
      "\n",
      "1 Терел ивать и разливать химические вещества следует соблюдая\n",
      "\n",
      "Ж.5.5.2 Воздушно-пенные огнетушители не должны применяться для:\n",
      "\n",
      "мерами;\n",
      "\n",
      "сечение и тип провода;\n",
      "\n",
      "® Оценка Заявок на участие в запросе предложений по критерию «Сроки поставки товара,\n",
      "\n",
      "\n",
      "\n",
      "суммирование данных no с записью полученных давных в памяти слотемы;\n",
      "\n",
      "\n",
      "\n",
      "(решения по установке и конфигурированию программных и анпаратных средств и\n",
      "\n",
      "Экземпляр АО «СНК»\n",
      "\n",
      "Просим вернуть по адресу:\n",
      "\n",
      "693004, г. Южно-Сахалинск,\n",
      "\n",
      "«Заказчик», в лице генерального директора Дойникова Юрия Андреевича, действующего на\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "color_dict = {\n",
    "    1 : (0, 0, 255),\n",
    "    2 : (0, 255, 0),\n",
    "    3 : (255, 0, 0),\n",
    "    4 : (0, 255, 255)\n",
    "}\n",
    "class2label = {\n",
    "    1: \"header\", \n",
    "    2: \"list\", \n",
    "    3: \"text\", \n",
    "    4: \"other\"\n",
    "}\n",
    "\n",
    "grouped_by_dock = defaultdict(list)\n",
    "for item in d.items():\n",
    "    key, (real_class, predicted_class) = item\n",
    "    file_name = key[1]\n",
    "    grouped_by_dock[file_name].append(item)\n",
    "\n",
    "\n",
    "for file_name, items in tqdm(grouped_by_dock.items()):\n",
    "    \n",
    "    img = None \n",
    "    for key, (real_class, predicted_class) in items:        \n",
    "        if real_class != predicted_class:\n",
    "            print(key[2])\n",
    "            print()\n",
    "            if img is None:\n",
    "                img = cv2.imread('docs/' + file_name)\n",
    "            (x, y, w, h) = key[0]\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), color_dict[predicted_class], 2)\n",
    "            cv2.putText(img, class2label[predicted_class] + \" \" + class2label[real_class], \n",
    "                        (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, \n",
    "                        color_dict[predicted_class], 2)\n",
    "    if img is not None:\n",
    "        cv2.imwrite('different_docs/' + file_name, img)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
