{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) parameters tune\n",
    "\n",
    "2) learning curve\n",
    "\n",
    "3) является ли предыдущая строка продолжением следующей - сделать лучше + тесты\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from sklearn.pipeline import make_pipeline, FeatureUnion\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import xgbfir\n",
    "from itertools import product\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_expr = [re.compile(r'\\d+(\\.\\d+)+\\D'), # 1.1.1 1\n",
    "            re.compile(r'\\d+[\\)\\}]'), # 1) 2\n",
    "            re.compile(r'\\w+(\\.\\w+)+\\W'), # 3\n",
    "            re.compile(r'[а-яА-Я\\d]+(\\.[а-яА-Я\\d]+)+\\W'), # b.b.b 4\n",
    "            re.compile(r'[\\wа-яА-Я]\\.\\W'), # b. 5\n",
    "            re.compile(r'[6а-яА-Яa-zA-Z][\\)\\}]'), # б) 6\n",
    "            re.compile(r'\\-|—'), # - 7\n",
    "            re.compile(r'®|\\*'), # * 8\n",
    "            re.compile(r'[a-zа-я]'), # строчная буква в начале 9\n",
    "            re.compile(r'[A-ZА-Я]'),  # заглавная буква в начале 10\n",
    "            re.compile(r'Раздел|Подраздел|Глава|Параграф|Секция|Часть|Статья'), # 11 \n",
    "            re.compile(r'[\\wа-я] ')] # 12\n",
    "\n",
    "def add_reg_features(line):\n",
    "    features = [0] * len(reg_expr)\n",
    "    i = 0\n",
    "    for expr in reg_expr:\n",
    "        match = expr.search(line)\n",
    "    \n",
    "        if match:\n",
    "            if match.start() == 0:\n",
    "                features[i] = 1\n",
    "        i += 1\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_reg_expr = [re.compile(r'.*\\.'),\n",
    "                re.compile(r'.*;'),\n",
    "                re.compile(r'.*:'),\n",
    "                re.compile(r'.*,'),\n",
    "                re.compile(r'.*[\\wа-яА-Я]'),\n",
    "                re.compile(r'[А-ЯA-Z\\.,\\s]+')] # uppercase\n",
    "\n",
    "def add_end_reg_features(line):\n",
    "    features = [0] * len(end_reg_expr)\n",
    "    i = 0\n",
    "    for expr in end_reg_expr:\n",
    "        match = expr.fullmatch(line)\n",
    "        if match:\n",
    "            features[i] = 1\n",
    "        i += 1\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1.1 -> 1.1.2\n",
    "# 1) -> 2)\n",
    "# 1. -> 2.\n",
    "# -\n",
    "\n",
    "# unit tests!!!\n",
    "# analyzing previous lines\n",
    "\n",
    "RE_LIST1 = re.compile(r'\\d+(\\.\\d+)+\\D') # 1.1.1\n",
    "RE_LIST2 = re.compile(r'\\d+[\\)\\.]\\s') # 1) 1.\n",
    "RE_LIST3 = re.compile(r'\\-|—') # -\n",
    "RE_LIST4 = re.compile(r'[a-zA-Zа-яА-Я][\\)\\.]\\s') # a)\n",
    "\n",
    "def list_continue(doc_info, line, line_num):\n",
    "    match = RE_LIST1.match(line)\n",
    "    if match:\n",
    "        last_num = int(match.group()[-2])\n",
    "        for i in range(line_num - 1, -1, -1):\n",
    "            doc_line = doc_info[i]['text']\n",
    "            match = RE_LIST1.match(doc_line)\n",
    "            if match:\n",
    "                return last_num == int(match.group()[-2]) + 1\n",
    "        return False\n",
    "    match = RE_LIST2.match(line)\n",
    "    if match:\n",
    "        last_num = int(match.group()[:-2])\n",
    "        for i in range(line_num - 1, -1, -1):\n",
    "            doc_line = doc_info[i]['text']\n",
    "            match = RE_LIST2.match(doc_line)\n",
    "            if match:\n",
    "                return last_num == int(match.group()[:-2]) + 1\n",
    "        return False\n",
    "    match = RE_LIST3.match(line)\n",
    "    if match:\n",
    "        for i in range(line_num - 1, -1, -1):\n",
    "            doc_line = doc_info[i]['text']\n",
    "            match = RE_LIST3.match(doc_line)\n",
    "            if match:\n",
    "                return True\n",
    "        return False\n",
    "    match = RE_LIST4.match(line)\n",
    "    if match:\n",
    "        last_num = ord(match.group()[-2])\n",
    "        for i in range(line_num - 1, -1, -1):\n",
    "            doc_line = doc_info[i]['text']\n",
    "            match = RE_LIST1.match(doc_line)\n",
    "            if match:\n",
    "                return last_num == ord(match.group()[-2]) + 1\n",
    "        return False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# font-weight detection\n",
    "\n",
    "def bold_mean_color(bbox, img, d_ksize, e_ksize):\n",
    "    x, y, w, h = bbox\n",
    "    crop_img = img[y:y + h, x:x + w]\n",
    "    kernel = np.ones((d_ksize, d_ksize),np.uint8)\n",
    "    dilation = cv2.dilate(crop_img, kernel, iterations = 1)\n",
    "    kernel = np.ones((e_ksize, e_ksize),np.uint8)\n",
    "    erosion = cv2.erode(dilation, kernel, iterations = 1)\n",
    "    avg_color_per_row = np.average(erosion, axis=0)\n",
    "    avg_color = np.average(avg_color_per_row, axis=0)\n",
    "    return np.average(avg_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount letters of the first word in line\n",
    "\n",
    "RE_WORD = re.compile(r'[a-zA-Zа-яА-Я]+')\n",
    "RE_FIRST = re.compile(r'\\S+\\s')\n",
    "\n",
    "def letters_cnt(line):\n",
    "    res = [0, 0, 0]\n",
    "    match = RE_WORD.search(line)\n",
    "    if match:\n",
    "        if match.start() == 0: # word in the beginning of the line\n",
    "            res[0] = len(match.group(0))\n",
    "    match = RE_FIRST.search(line)\n",
    "    if match:\n",
    "        if match.start() == 0: # some characters in the beginning of the line\n",
    "            res[1] = len(match.group(0))\n",
    "    words = line.split()\n",
    "    if len(words) >= 2:\n",
    "        res[2] = len(words[1])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bold_mean_colors(bbox, img, num):\n",
    "    res = []\n",
    "    for i in range(2, num + 1):\n",
    "        res.append(bold_mean_color(bbox, img, i, i ))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddImgFeatures:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X - [{\"name\": \"doc_name\", \"entities\": [{\"text\": \"\", \"bbox\": []}]}]\n",
    "        returns features\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        for doc in X:\n",
    "            doc_features = []\n",
    "            doc_name = doc['name']\n",
    "            doc_info = doc['entities']\n",
    "            num_bold = 7\n",
    "            img = cv2.imread('docs/' + doc_name)\n",
    "            heigth = img.shape[0]\n",
    "            width = img.shape[1]\n",
    "            i = 0\n",
    "            for line_info in doc_info:\n",
    "                list_cont = list_continue(doc_info, line_info['text'], i) # several different features???\n",
    "                word_cnt = len(line_info['text'].split())\n",
    "                line_length = len(line_info['text'])\n",
    "                \n",
    "                line_features = [line_info['bbox'][0] / width, # left\n",
    "                                 line_info['bbox'][1] / heigth, # top\n",
    "                                 line_info['bbox'][3] / heigth, # height\n",
    "                                 line_length, word_cnt, list_cont] \n",
    "                line_features += add_bold_mean_colors(line_info['bbox'], img, num_bold)\n",
    "                line_features += add_reg_features(line_info['text'])\n",
    "                line_features += add_end_reg_features(line_info['text'])\n",
    "                line_features += letters_cnt(line_info['text'])\n",
    "                doc_features.append(line_features)\n",
    "                i += 1\n",
    "            features.append(doc_features)\n",
    "        return features\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prev_next_features(doc, line_features, num_line):\n",
    "    \"\"\"\n",
    "    doc - list of line_features\n",
    "    line_features - list of features\n",
    "    \"\"\"\n",
    "    add_f = [0] * len(line_features)\n",
    "    extended_doc = [add_f] * 4 + doc + [add_f] * 4\n",
    "    prev_features = reduce(lambda x, y: x + y, \n",
    "                           extended_doc[num_line: num_line + 4])\n",
    "    next_features = reduce(lambda x, y: x + y, \n",
    "                           extended_doc[num_line + 5: num_line + 9])\n",
    "    return line_features + prev_features + next_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddPrevNextFeatures:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X - list of doc_features\n",
    "        doc_features - list of line_features\n",
    "        \n",
    "        for each line 4 previous and 4 next features added\n",
    "        result list of lines features\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        for doc_features in X:\n",
    "            i = 0\n",
    "            l = len(doc_features)\n",
    "            mean_left = np.sum(list(map(lambda x: x[0], doc_features))) / l\n",
    "            mean_heigth = np.sum(list(map(lambda x: x[2], doc_features))) / l\n",
    "            mean_line_length = np.sum(list(map(lambda x: x[3], doc_features))) / l\n",
    "            mean_bold_color = np.sum(list(map(lambda x: x[9], doc_features))) / l # bold5\n",
    "            # mean word letters cnt, mean word cnt\n",
    "            for line_features in doc_features:\n",
    "                new_features = add_prev_next_features(doc_features, line_features, i)\n",
    "                i += 1\n",
    "                new_features += [mean_left, mean_heigth, mean_line_length, mean_bold_color]\n",
    "                result.append(new_features)\n",
    "        return np.array(result)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2class = {\n",
    "    \"header\" : 1,\n",
    "    \"list\" : 2,\n",
    "    \"text\" : 3,\n",
    "    \"other\" : 4\n",
    "}\n",
    "\n",
    "with open(\"data.json\", \"r\") as read_file:\n",
    "    docs = json.load(read_file)\n",
    "    y = []\n",
    "    for doc in docs:\n",
    "        elem = [label2class[line['label']] for line in doc['entities']]\n",
    "        y.append(elem)\n",
    "    X = []\n",
    "    for doc in docs:\n",
    "        elem = {}\n",
    "        elem['name'] = doc['name']\n",
    "        elem['entities'] = [{'text': line_info['text'], \n",
    "                        'bbox': [line_info['x'], line_info['y'],\n",
    "                                line_info['width'], line_info['height']]}\n",
    "                      for line_info in doc['entities']]\n",
    "        X.append(elem)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anastasiabogatenkova/miniconda3/envs/doc-py37/lib/python3.7/site-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7115d3bb756643f399972559d370e9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9923355077882295\n",
      "0.992139576318784\n",
      "0.9809193279385992\n",
      "\n",
      "[0.9923355077882295, 0.992139576318784, 0.9809193279385992]\n",
      "0.9884648040152042\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(AddImgFeatures(),\n",
    "                    AddPrevNextFeatures(),\n",
    "                    XGBClassifier())\n",
    "\n",
    "scores = []\n",
    "\n",
    "n_folds = 3\n",
    "kf = KFold(n_splits=n_folds)\n",
    "for train_index, test_index in tqdm(kf.split(X), total=n_folds):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train = np.array(reduce(lambda x1, x2: x1 + x2, y[train_index]))\n",
    "    y_test = np.array(reduce(lambda x1, x2: x1 + x2, y[test_index]))\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred, average='macro')\n",
    "    print(score)\n",
    "    scores.append(score)\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9902820635073686"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor = make_pipeline(AddImgFeatures(),\n",
    "                                  AddPrevNextFeatures())\n",
    "xgb_cmodel = XGBClassifier()\n",
    "\n",
    "X, y = shuffle(X, y, random_state=1)\n",
    "X_train, X_test = X[:400], X[400:]\n",
    "y_train = np.array(reduce(lambda x1, x2: x1 + x2, y[:400]))\n",
    "y_test = np.array(reduce(lambda x1, x2: x1 + x2, y[400:]))\n",
    "\n",
    "X_train = feature_extractor.fit_transform(X_train)\n",
    "X_test = feature_extractor.fit_transform(X_test)\n",
    "\n",
    "xgb_cmodel.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_cmodel.predict(X_test)\n",
    "score = f1_score(y_test, y_pred, average='macro')\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names(names):\n",
    "    feature_names = names.copy()\n",
    "    for i in range(1, 5):\n",
    "        for name in names:\n",
    "            feature_names.append(str(i) + '_prev_' + name)\n",
    "    for i in range(1, 5):\n",
    "        for name in names:\n",
    "            feature_names.append(str(i) + '_next_' + name)\n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = get_feature_names(['left', 'top', 'height',\n",
    "                                   'line_length', 'word_cnt', 'list_cont',\n",
    "                                   'bold2', 'bold3', 'bold4', 'bold5', 'bold6', 'bold7',\n",
    "                                   'reg1', 'reg2','reg3', 'reg4', 'reg5', 'reg6', \n",
    "                                   'reg7', 'reg8', 'reg9', 'reg10', 'reg11', 'reg12',\n",
    "                                   'end_reg1', 'end_reg2', 'end_reg3', \n",
    "                                   'end_reg4', 'end_reg5', 'uppercase',\n",
    "                                   'word_letters_cnt', 'first_cnt', 'second_cnt'])\n",
    "\n",
    "feature_names += ['mean_left', 'mean_height', 'mean_line_length', 'mean_bold_color']\n",
    "\n",
    "xgbfir.saveXgbFI(xgb_cmodel, feature_names=feature_names, \n",
    "                 OutputXlsxFile='fearures_importances.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_test [{\"name\": \"doc_name\", \"entities\": [{\"text\": \"\", \"bbox\": []}]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[:400], X[400:]\n",
    "\n",
    "d = {}\n",
    "i = 0\n",
    "for doc_info in X_test:\n",
    "    for line_info in doc_info['entities']:\n",
    "        d[(tuple(line_info['bbox']), doc_info['name'], \n",
    "           line_info[\"text\"])] = [y_test[i], y_pred[i]]\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anastasiabogatenkova/miniconda3/envs/doc-py37/lib/python3.7/site-packages/ipykernel_launcher.py:21: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48d1d0b11e3419c981024f074fa1f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1. Техническая часть проекта в составе:\n",
      "\n",
      "4. Требования к технической локументации\n",
      "\n",
      "безопасности на объектах сооружения АЭС и их взаимодействие с\n",
      "\n",
      "4.1 к разделу 3 настоящей документации), копиями исполненных контрактов/договоров на\n",
      "\n",
      "ОХРАНА ОКРУЖАЮЩЕЙ СРЕДЫ\n",
      "\n",
      "3.26 огнезащитная обработка строительной конструкции:\n",
      "\n",
      "— ПО), каналы связи, программные средства. Все технические средства, задействованные в\n",
      "\n",
      "— не менее 6 м;\n",
      "\n",
      "1, Пи Ш степеней огнестойкости класса СО — не менее 9 м;\n",
      "\n",
      "3.68 степень огнестойкости зданий, сооружений, строений и\n",
      "\n",
      "— не менее 6 м;\n",
      "\n",
      "1, Пи Ш степеней огнестойкости класса СО — не менее 9 м;\n",
      "\n",
      "3.20 средетва индивидуальной и коллективной защиты работников:\n",
      "\n",
      "Открытый запрос котировок в электронной форме (далее также - Открытый запрос\n",
      "\n",
      "— ПО), каналы связи, программные средства. Все технические средства, задействованные в\n",
      "\n",
      "5-4. В ходе рассмотрения заявок Заказчик вправе направить запросы Участникам процедуры закупки\n",
      "\n",
      "СОДЕРЖАНИЕ\n",
      "\n",
      "10.8 Резервные пульты управления (резервные щиты управления)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "color_dict = {\n",
    "    1 : (0, 0, 255),\n",
    "    2 : (0, 255, 0),\n",
    "    3 : (255, 0, 0),\n",
    "    4 : (0, 255, 255)\n",
    "}\n",
    "class2label = {\n",
    "    1: \"header\", \n",
    "    2: \"list\", \n",
    "    3: \"text\", \n",
    "    4: \"other\"\n",
    "}\n",
    "\n",
    "grouped_by_dock = defaultdict(list)\n",
    "for item in d.items():\n",
    "    key, (real_class, predicted_class) = item\n",
    "    file_name = key[1]\n",
    "    grouped_by_dock[file_name].append(item)\n",
    "\n",
    "\n",
    "for file_name, items in tqdm(grouped_by_dock.items()):\n",
    "    \n",
    "    img = None \n",
    "    for key, (real_class, predicted_class) in items:        \n",
    "        if real_class != predicted_class:\n",
    "            print(key[2])\n",
    "            print()\n",
    "            if img is None:\n",
    "                img = cv2.imread('docs/' + file_name)\n",
    "            (x, y, w, h) = key[0]\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), color_dict[predicted_class], 2)\n",
    "            cv2.putText(img, class2label[predicted_class] + \n",
    "                        \" \" + class2label[real_class], \n",
    "                        (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, \n",
    "                        color_dict[predicted_class], 2)\n",
    "    if img is not None:\n",
    "        cv2.imwrite('different_docs/' + file_name, img)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
