{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) посмотреть, где ошибается классификатор\n",
    "\n",
    "2) тюнить параметры\n",
    "\n",
    "3) важность признаков +\n",
    "\n",
    "4) переразметить некоторые документы +\n",
    "\n",
    "5) кривая обучения\n",
    "\n",
    "6) несколько признаков с разным распознаванием жирности\n",
    "\n",
    "7) средний цвет для распознавания жирности\n",
    "\n",
    "8) является ли предыдущая строка продолжением следующей\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from sklearn.pipeline import make_pipeline, FeatureUnion\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import xgbfir\n",
    "from itertools import product\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_expr = [re.compile(r'\\d+(\\.\\d+)+\\D'), # 1.1.1 1\n",
    "            re.compile(r'\\d+[\\)\\}]'), # 1) 2\n",
    "            re.compile(r'\\w+(\\.\\w+)+\\W'), # 3\n",
    "            re.compile(r'[а-яА-Я\\d]+(\\.[а-яА-Я\\d]+)+\\W'), # b.b.b 4\n",
    "            re.compile(r'[\\wа-яА-Я]\\.\\W'), # b. 5\n",
    "            re.compile(r'[6а-яА-Яa-zA-Z][\\)\\}]'), # б) 6\n",
    "            re.compile(r'\\-|—'), # - 7\n",
    "            re.compile(r'®|\\*'), # * 8\n",
    "            re.compile(r'[a-zа-я]'), # строчная буква в начале 9\n",
    "            re.compile(r'[A-ZА-Я]'),  # заглавная буква в начале 10\n",
    "            re.compile(r'Раздел|Подраздел|Глава|Параграф|Секция|Часть|Статья')] # 11\n",
    "\n",
    "def add_reg_features(line):\n",
    "    features = [0] * len(reg_expr)\n",
    "    i = 0\n",
    "    for expr in reg_expr:\n",
    "        match = expr.search(line)\n",
    "    \n",
    "        if match:\n",
    "            if match.start() == 0:\n",
    "                features[i] = 1\n",
    "        i += 1\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_reg_expr = [re.compile(r'.*\\.'),\n",
    "                re.compile(r'.*;'),\n",
    "                re.compile(r'.*:'),\n",
    "                re.compile(r'.*,'),\n",
    "                re.compile(r'.*[\\wа-яА-Я]')]\n",
    "\n",
    "def add_end_reg_features(line):\n",
    "    features = [0] * len(end_reg_expr)\n",
    "    i = 0\n",
    "    for expr in end_reg_expr:\n",
    "        match = expr.fullmatch(line)\n",
    "        if match:\n",
    "            features[i] = 1\n",
    "        i += 1\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1.1 -> 1.1.2\n",
    "# 1) -> 2)\n",
    "# 1. -> 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_bbox_size(bboxes):\n",
    "    \"\"\"\n",
    "    bboxes - list [{\"text\": \"\", \"bbox\": []}, {} ...]\n",
    "    returns (mean_height, mean_width)\n",
    "    \"\"\"\n",
    "    lefts = np.sum(list(map(lambda x: x['bbox'][0], bboxes)))\n",
    "    widths = np.sum(list(map(lambda x: x['bbox'][2], bboxes)))\n",
    "    heigths = np.sum(list(map(lambda x: x['bbox'][3], bboxes)))\n",
    "    num_bboxes = len(bboxes)\n",
    "    \n",
    "    return (lefts / num_bboxes, heigths / num_bboxes, widths / num_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more complex font-weight detection\n",
    "\n",
    "def bold_mean_color(bbox, img, d_ksize, e_ksize):\n",
    "    x, y, w, h = bbox\n",
    "    crop_img = img[y:y + h, x:x + w]\n",
    "    kernel = np.ones((d_ksize, d_ksize),np.uint8)\n",
    "    dilation = cv2.dilate(crop_img, kernel, iterations = 1)\n",
    "    kernel = np.ones((e_ksize, e_ksize),np.uint8)\n",
    "    erosion = cv2.erode(dilation, kernel, iterations = 1)\n",
    "    avg_color_per_row = np.average(erosion, axis=0)\n",
    "    avg_color = np.average(avg_color_per_row, axis=0)\n",
    "    return np.average(avg_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add simple font-weight detection\n",
    "\n",
    "def mean_color(bbox, img):\n",
    "    x, y, w, h = bbox\n",
    "    crop_img = img[y:y + h, x:x + w]\n",
    "    avg_color_per_row = np.average(crop_img, axis=0)\n",
    "    avg_color = np.average(avg_color_per_row, axis=0)\n",
    "    return np.average(avg_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amount letters of the first word in line\n",
    "\n",
    "RE_WORD = re.compile(r'[a-zA-Zа-яА-Я]+')\n",
    "\n",
    "def letters_cnt(line):\n",
    "    match = RE_WORD.search(line)\n",
    "\n",
    "    if match:\n",
    "        if match.start() == 0: # word in the beginning of the line\n",
    "            return len(match.group(0))\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bold_mean_colors(bbox, img, num):\n",
    "    res = []\n",
    "    for i in range(2, num + 1):\n",
    "        res.append(bold_mean_color(bbox, img, i, i))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddImgFeatures:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X - [{\"name\": \"doc_name\", \"entities\": [{\"text\": \"\", \"bbox\": []}]}]\n",
    "        returns features\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        for doc in X:\n",
    "            doc_features = []\n",
    "            doc_name = doc['name']\n",
    "            doc_info = doc['entities']\n",
    "            num_bold = 7\n",
    "            sum_avg_colors = 0\n",
    "            sum_line_cnt = 0\n",
    "            sum_bold_colors = [0] * (num_bold - 1)\n",
    "            mean_left, mean_heigth, mean_width = mean_bbox_size(doc_info)\n",
    "            img = cv2.imread('docs/' + doc_name)\n",
    "            avg_color_per_row = np.average(img, axis=0)\n",
    "            avg_color = np.average((np.average(avg_color_per_row, axis=0)))     \n",
    "            heigth = img.shape[0]\n",
    "            width = img.shape[1]\n",
    "            for line_info in doc_info:\n",
    "                line_color = mean_color(line_info['bbox'], img)\n",
    "                bold_line_colors = add_bold_mean_colors(line_info['bbox'], img, num_bold)\n",
    "                for i, col in enumerate(bold_line_colors):\n",
    "                    sum_bold_colors[i] += col\n",
    "                \n",
    "                line_features = [line_info['bbox'][0] / width,\n",
    "                                line_info['bbox'][1] / heigth,\n",
    "                                line_info['bbox'][2] / width,\n",
    "                                line_info['bbox'][3] / heigth,\n",
    "                                mean_left, mean_heigth, mean_width,\n",
    "                                line_color, avg_color]\n",
    "                line_features += bold_line_colors\n",
    "                sum_avg_colors += line_color\n",
    "                line_features += add_reg_features(line_info['text'])\n",
    "                line_features += add_end_reg_features(line_info['text'])\n",
    "                word_cnt = len(line_info['text'].split())\n",
    "                word_letters_cnt = letters_cnt(line_info['text'])\n",
    "                line_cnt = len(line_info['text'])\n",
    "                line_features += [word_letters_cnt, line_cnt, word_cnt]\n",
    "                sum_line_cnt += line_cnt\n",
    "                doc_features.append(line_features)\n",
    "            l = len(doc_info)\n",
    "            mean_line_color = sum_avg_colors / l\n",
    "            mean_bold_colors = [col / l for col in sum_bold_colors]\n",
    "            mean_line_cnt = sum_line_cnt / l\n",
    "            for line_features in doc_features:\n",
    "                line_features += [mean_line_cnt, mean_line_color]\n",
    "                line_features += mean_bold_colors\n",
    "            features.append(doc_features)\n",
    "        return features\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prev_next_features(doc, line_features, num_line):\n",
    "    \"\"\"\n",
    "    doc - list of line_features\n",
    "    line_features - list of features\n",
    "    \"\"\"\n",
    "    add_f = [0] * len(line_features)\n",
    "    extended_doc = [add_f] * 4 + doc + [add_f] * 4\n",
    "    prev_features = reduce(lambda x, y: x + y, \n",
    "                           extended_doc[num_line: num_line + 4])\n",
    "    next_features = reduce(lambda x, y: x + y, \n",
    "                           extended_doc[num_line + 5: num_line + 9])\n",
    "    return line_features + prev_features + next_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddPrevNextFeatures:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X - list of doc_features\n",
    "        doc_features - list of line_features\n",
    "        \n",
    "        for each line 4 previous and 4 next features added\n",
    "        result list of lines features\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        for doc_features in X:\n",
    "            i = 0\n",
    "            for line_features in doc_features:\n",
    "                new_features = add_prev_next_features(doc_features, line_features, i)\n",
    "                i += 1\n",
    "                result.append(new_features)\n",
    "        return np.array(result)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2class = {\n",
    "    \"header\" : 1,\n",
    "    \"list\" : 2,\n",
    "    \"text\" : 3,\n",
    "    \"other\" : 4\n",
    "}\n",
    "\n",
    "with open(\"data.json\", \"r\") as read_file:\n",
    "    docs = json.load(read_file)\n",
    "    y = []\n",
    "    for doc in docs:\n",
    "        elem = [label2class[line['label']] for line in doc['entities']]\n",
    "        y.append(elem)\n",
    "    X = []\n",
    "    for doc in docs:\n",
    "        elem = {}\n",
    "        elem['name'] = doc['name']\n",
    "        elem['entities'] = [{'text': line_info['text'], \n",
    "                        'bbox': [line_info['x'], line_info['y'],\n",
    "                                line_info['width'], line_info['height']]}\n",
    "                      for line_info in doc['entities']]\n",
    "        X.append(elem)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters tuning:\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anastasiabogatenkova/miniconda3/envs/doc-py37/lib/python3.7/site-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "defad89e6c874a8080b7902e41dfb550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0.917814328754872, 0.9004177046081319, 0.8879187854155478]\n",
      "0.9020502729261839\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(AddImgFeatures(),\n",
    "                    AddPrevNextFeatures(),\n",
    "                    XGBClassifier())\n",
    "\n",
    "scores = []\n",
    "\n",
    "n_folds = 3\n",
    "kf = KFold(n_splits=n_folds)\n",
    "for train_index, test_index in tqdm(kf.split(X), total=n_folds):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train = np.array(reduce(lambda x1, x2: x1 + x2, y[train_index]))\n",
    "    y_test = np.array(reduce(lambda x1, x2: x1 + x2, y[test_index]))\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature importances https://github.com/limexp/xgbfir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "кривая обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = make_pipeline(AddImgFeatures(),\n",
    "                                  AddPrevNextFeatures())\n",
    "scores = [] # (train_cnt, score)\n",
    "train_num = list(range(500, 40, -30))\n",
    "\n",
    "for train_cnt in tqdm(train_num):\n",
    "    xgb_cmodel = XGBClassifier(nthread=4)\n",
    "    X, y = X, y = shuffle(X, y, random_state=0)\n",
    "    X_train, X_test = X[:train_cnt], X[train_cnt:]\n",
    "    y_train = np.array(reduce(lambda x1, x2: x1 + x2, y[:train_cnt]))\n",
    "    y_test = np.array(reduce(lambda x1, x2: x1 + x2, y[train_cnt:]))\n",
    "\n",
    "    X_train = feature_extractor.fit_transform(X_train)\n",
    "    X_test = feature_extractor.fit_transform(X_test)\n",
    "\n",
    "    xgb_cmodel.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = xgb_cmodel.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred, average='macro')\n",
    "    print(train_cnt, score)\n",
    "    scores.append((train_cnt, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.plot(train_num, list(map(lambda x: x[1],scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8879187854155478"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor = make_pipeline(AddImgFeatures(),\n",
    "                                  AddPrevNextFeatures())\n",
    "xgb_cmodel = XGBClassifier()\n",
    "\n",
    "X_train, X_test = X[:400], X[400:]\n",
    "y_train = np.array(reduce(lambda x1, x2: x1 + x2, y[:400]))\n",
    "y_test = np.array(reduce(lambda x1, x2: x1 + x2, y[400:]))\n",
    "\n",
    "X_train = feature_extractor.fit_transform(X_train)\n",
    "X_test = feature_extractor.fit_transform(X_test)\n",
    "\n",
    "xgb_cmodel.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_cmodel.predict(X_test)\n",
    "score = f1_score(y_test, y_pred, average='macro')\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names(names):\n",
    "    feature_names = names.copy()\n",
    "    for i in range(1, 5):\n",
    "        for name in names:\n",
    "            feature_names.append(str(i) + '_prev_' + name)\n",
    "    for i in range(1, 5):\n",
    "        for name in names:\n",
    "            feature_names.append(str(i) + '_next_' + name)\n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = get_feature_names(['left', 'top', 'wigth', 'height', \n",
    "                'mean_left', 'mean_height', 'mean_width',\n",
    "                'line_color', 'avg_color',\n",
    "                'bold2', 'bold3', 'bold4', 'bold5', 'bold6', 'bold7',\n",
    "                'reg1', 'reg2',\n",
    "                'reg3', 'reg4', 'reg5', 'reg6', 'reg7',\n",
    "                'reg8', 'reg9', 'reg10', 'reg11',\n",
    "                'end_reg1', 'end_reg2', 'end_reg3', 'end_reg4', 'end_reg5',\n",
    "                'word_letters_cnt', 'line_cnt', 'word_cnt', 'mean_line_cnt',\n",
    "                'mean_line_color', 'mean_bold2', \n",
    "                'mean_bold3', 'mean_bold4', 'mean_bold5',\n",
    "                'mean_bold6', 'mean_bold7'])\n",
    "\n",
    "xgbfir.saveXgbFI(xgb_cmodel, feature_names=feature_names, \n",
    "                 OutputXlsxFile='fearures_importances.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_test [{\"name\": \"doc_name\", \"entities\": [{\"text\": \"\", \"bbox\": []}]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[:400], X[400:]\n",
    "\n",
    "d = {}\n",
    "i = 0\n",
    "for doc_info in X_test:\n",
    "    for line_info in doc_info['entities']:\n",
    "        d[(tuple(line_info['bbox']), doc_info['name'], line_info[\"text\"])] = [y_test[i], y_pred[i]]\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anastasiabogatenkova/miniconda3/envs/doc-py37/lib/python3.7/site-packages/ipykernel_launcher.py:21: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a29559340a4f85a4319e3c2aaac940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начальник СТОС Wy С.Н. Кирюшин\n",
      "\n",
      "5.10.3. решение о допуске Участника процедуры закупки к участию в запросе предложений и о\n",
      "\n",
      "® условия оплаты - 10 (ОЪазс);\n",
      "\n",
      "3 В случае, если хотя бы один из Участников является налогоплательщиком, применяющим упрощенную систему\n",
      "\n",
      "7. Мероприятия по контролю качества разрешительной, проектной\n",
      "\n",
      "(рабочей), проектов производства работ (технологических регламентов),\n",
      "\n",
      "исполнительной документации.\n",
      "\n",
      "занесенные в общий журнал производства работ.\n",
      "\n",
      "(описание вида производства работ, ведение исполнительной документации,\n",
      "\n",
      "Дополнительная информация:\n",
      "\n",
      "Приложение к конкурсной документации:\n",
      "\n",
      "\n",
      "\n",
      "И.о. начальника УЗ Л.Г. Возчикова\n",
      "\n",
      "испокон еее\n",
      "\n",
      "5.2.3. Надлежаще исполнять иные принятые на себя обязательства.\n",
      "\n",
      "6.2. Поставщик по настоящему Договору обязан:\n",
      "\n",
      "6.2.5. Надлежаще исполнять иные принятые на себя обязательств.\n",
      "\n",
      "4. Участник закупки подтверждает, что согласен выполнить работы, являющиеся предметом\n",
      "\n",
      "М.П. (для юридических лиц)\n",
      "\n",
      "'рузка осуществляется силами Грузополучателя (самовывоз), либо Грузоперевозчиком\n",
      "\n",
      "13. Срок и место получения документов для участника: с 13.08.2019 г., с документами можно ознакомиться на\n",
      "\n",
      "14. Порядок, место и срок подачи заявки на поставку товара (выполнение работ/оказание услуг):\n",
      "\n",
      "16. Дата, время и место рассмотрения поступивших предложений: «22» августа 2019 года, АО «Витимэнерго»,\n",
      "\n",
      "17. Порядок подведения итогов конкурентной закупки: Порядок подведения итогов конкурентной закупки указан\n",
      "\n",
      "18. Особенности участия субъектов малого и среднего предпринимательства: только для субъектов МСП.\n",
      "\n",
      "19. Дата, время и место определения победителя: «23» августа 2019 года, АО «Витимэнерго», по адресу:\n",
      "\n",
      "21. Заказчик (Покупатель), организующий запрос котировок в электронной форме вправе отказаться от\n",
      "\n",
      "22. Порядок и срок отзыва заявок на участие в запросе котировок: участник может отозвать заявку, оповестив\n",
      "\n",
      "23. Срок подписания договора поставки с победителем: Договор может быть подписан на основании итогового\n",
      "\n",
      "24. Опцион: Заказчик (Покупатель) оставляет за собой право воспользоваться опционом в пределах 30% от общей\n",
      "\n",
      "25. Переторжка: Заказчик (Покупатель) оставляет за собой право проведения переторжки.\n",
      "\n",
      "26. Сведения об участнике конкурентной процедуры должны отсутствовать в Реестре недобросовестных\n",
      "\n",
      "а) осмотр основных конструкций градирен (элементов башни,\n",
      "\n",
      "2.2. Подрядчик выполняет работы в соответствии с Техническим заданием (Приложение № 1)\n",
      "\n",
      "— [32];\n",
      "\n",
      "3.52 предел огнестойкости конструкции (заполнения проемов\n",
      "\n",
      "состояние ходовой части тележки (для передвижного огнетушителя);\n",
      "\n",
      "Ж:3.9 В том случае, если величина утечки за: год вытесняющего газа или ОТВ\n",
      "\n",
      "Привести в текстовой части\n",
      "\n",
      "3. Требования к документации технико-коммерческого предложения (ТК)\n",
      "\n",
      "3.2.1. Услуги должны выполняться в соответствии:\n",
      "\n",
      "Подраздел 3.3 Требования к гарантийным обязательствам оказываемых услуг\n",
      "\n",
      "Подраздел 3.5 Требования к безопасности оказания услуг и безопасности результата\n",
      "\n",
      "оказанных услуг\n",
      "\n",
      "Подраздел 3.6 Требования по обучению персонала Заказчика\n",
      "\n",
      "Подраздел 337 Требования к составу технического предложения участника\n",
      "\n",
      "Подраздел 4.1 Описание конечного результата оказанных услуг\n",
      "\n",
      "Подраздел 4.2. Требования по приемке услуг\n",
      "\n",
      "2.5. Приемка Товара по количеству и ассортименту производится при его вручении Покупателю и\n",
      "\n",
      "3.1. Сумма договора составляет | 502 733,17 (Один миллион пятьсот две тысячи семьсот тридцать\n",
      "\n",
      "счет Поставщика, открытый Поставщиком в соответствии с Федеральным законом от 29.12.2012 №275-ФЗ\n",
      "\n",
      "4.1. Головным исполнителем выбран уполномоченный банк - ВТБ (ПАО).\n",
      "\n",
      "Б.10 Руководитель. организаций (производитель работ) обеспечивает место\n",
      "\n",
      "10кВ рубящего или качающегося типа. Все стальные части разъединителя, в том\n",
      "\n",
      "5.1 Окрасочные работы:\n",
      "\n",
      "2.12.4.\n",
      "\n",
      "2.13. Подрядчик после окончания строительно-монтажных и пусконаладочных работ\n",
      "\n",
      "представляет следующую документацию:\n",
      "\n",
      "2.13.4. Акты освидетельствования скрытых работ;\n",
      "\n",
      "О - производство работ в объёме опробования.\n",
      "\n",
      "1.6. Особые условия.\n",
      "\n",
      "cook\n",
      "\n",
      "SA\n",
      "\n",
      "физическим объёмам работ, включенным в ведомость объёмов работ или акт технического\n",
      "\n",
      "проверки сметной стоимости капитального ремонта.\n",
      "\n",
      "3.4. Вывод о достоверности или недостоверности определения сметной стоимости строительства,\n",
      "\n",
      "реконструкции, капитального ремонта объекта капитального строительства:\n",
      "\n",
      "\n",
      "\n",
      "1 Терел ивать и разливать химические вещества следует соблюдая\n",
      "\n",
      "3.70 работа вблизи действующего оборудования: Работа ближе | м от\n",
      "\n",
      "Ж.5.5.2 Воздушно-пенные огнетушители не должны применяться для:\n",
      "\n",
      "сечение и тип провода;\n",
      "\n",
      "\n",
      "\n",
      "8. Основные нормативно-технические документы, определяющие\n",
      "\n",
      "р/сч 40502810838290000153 в ПАО Сбербанк, г. Москва\n",
      "\n",
      "суммирование данных no с записью полученных давных в памяти слотемы;\n",
      "\n",
      "\n",
      "\n",
      "(решения по установке и конфигурированию программных и анпаратных средств и\n",
      "\n",
      "т.п.);\n",
      "\n",
      "Экземпляр АО «СНК»\n",
      "\n",
      "Просим вернуть по адресу:\n",
      "\n",
      "693004, г. Южно-Сахалинск,\n",
      "\n",
      "«Заказчик», в лице генерального директора Дойникова Юрия Андреевича, действующего на\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "color_dict = {\n",
    "    1 : (0, 0, 255),\n",
    "    2 : (0, 255, 0),\n",
    "    3 : (255, 0, 0),\n",
    "    4 : (0, 255, 255)\n",
    "}\n",
    "class2label = {\n",
    "    1: \"header\", \n",
    "    2: \"list\", \n",
    "    3: \"text\", \n",
    "    4: \"other\"\n",
    "}\n",
    "\n",
    "grouped_by_dock = defaultdict(list)\n",
    "for item in d.items():\n",
    "    key, (real_class, predicted_class) = item\n",
    "    file_name = key[1]\n",
    "    grouped_by_dock[file_name].append(item)\n",
    "\n",
    "\n",
    "for file_name, items in tqdm(grouped_by_dock.items()):\n",
    "    \n",
    "    img = None \n",
    "    for key, (real_class, predicted_class) in items:        \n",
    "        if real_class != predicted_class:\n",
    "            print(key[2])\n",
    "            print()\n",
    "            if img is None:\n",
    "                img = cv2.imread('docs/' + file_name)\n",
    "            (x, y, w, h) = key[0]\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), color_dict[predicted_class], 2)\n",
    "            cv2.putText(img, class2label[predicted_class] + \" \" + class2label[real_class], \n",
    "                        (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, \n",
    "                        color_dict[predicted_class], 2)\n",
    "    if img is not None:\n",
    "        cv2.imwrite('different_docs/' + file_name, img)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
