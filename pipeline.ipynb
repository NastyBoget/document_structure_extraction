{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1) размечалка + манифест +\n",
    "\n",
    "2) признаки на основе предыдущих (следующих) строк +\n",
    "\n",
    "3) countvectorizer по первому второму словам +\n",
    "\n",
    "4) признак - средний размер баундин бокса +\n",
    "\n",
    "5) gboost +, xgboost +\n",
    "\n",
    "6) жирность +\n",
    "\n",
    "7) кросс-валидация по группам +\n",
    "\n",
    "8) посмотреть, где ошибается классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from functools import cmp_to_key\n",
    "from functools import reduce\n",
    "from sklearn.pipeline import make_pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score, cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_expr = [re.compile(r'\\d+(\\.\\d+)+\\D'), # 1.1.1\n",
    "            re.compile(r'\\d\\)'), # 1)\n",
    "            re.compile(r'\\w(\\.\\w)+\\W'), # b.b.b\n",
    "            re.compile(r'[а-яА-Я\\d](\\.[а-яА-Я\\d])+\\W'), # б.б.б\n",
    "            re.compile(r'[a-zA-Z]\\)'), # a)\n",
    "            re.compile(r'[a-zA-Z]\\.\\W'), # b.\n",
    "            re.compile(r'[а-яА-Я]\\)'), # б)\n",
    "            re.compile(r'[а-яА-Я]\\.\\W'), # б.\n",
    "            re.compile(r'\\-'), # -\n",
    "            re.compile(r'\\*'), # *\n",
    "            re.compile(r'Раздел|Подраздел|Глава|Параграф|Секция|Часть|Статья')]\n",
    "\n",
    "def add_reg_features(line):\n",
    "    features = [0] * len(reg_expr)\n",
    "    i = 0\n",
    "    for expr in reg_expr:\n",
    "        match = expr.search(line)\n",
    "    \n",
    "        if match:\n",
    "            if match.start() == 0:\n",
    "                features[i] = 1\n",
    "                return features\n",
    "        i += 1\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_bbox_size(bboxes):\n",
    "    \"\"\"\n",
    "    bboxes - list [{\"text\": \"\", \"bbox\": []}, {} ...]\n",
    "    returns (mean_height, mean_width)\n",
    "    \"\"\"\n",
    "    heigths = np.sum(list(map(lambda x: x['bbox'][2], bboxes)))\n",
    "    widths = np.sum(list(map(lambda x: x['bbox'][3], bboxes)))\n",
    "    num_bboxes = len(bboxes)\n",
    "    \n",
    "    return (heigths / num_bboxes, widths / num_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add simple font-weight\n",
    "\n",
    "def mean_color(bbox, img):\n",
    "    x, y, w, h = bbox\n",
    "    crop_img = img[y:y + h, x:x + w]\n",
    "    avg_color_per_row = np.average(crop_img, axis=0)\n",
    "    avg_color = np.average(avg_color_per_row, axis=0)\n",
    "    return list(avg_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddImgFeatures:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X - [{\"name\": \"doc_name\", \"entities\": [{\"text\": \"\", \"bbox\": []}]}]\n",
    "        returns features [normalized bbox sizes, normalized mean size of bbox]\n",
    "        [normalized left, normalized top,\n",
    "        normalized width, normalized height,\n",
    "        mean height, mean width]\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        for doc in X:\n",
    "            doc_features = []\n",
    "            doc_name = doc['name']\n",
    "            doc_info = doc['entities']\n",
    "            mean_heigth, mean_width = mean_bbox_size(doc_info)\n",
    "            img = cv2.imread('docs/' + doc_name)\n",
    "            heigth = img.shape[0]\n",
    "            width = img.shape[1]\n",
    "            for line_info in doc_info:\n",
    "                line_features = [line_info['bbox'][0] / width,\n",
    "                                line_info['bbox'][1] / heigth,\n",
    "                                line_info['bbox'][2] / width,\n",
    "                                line_info['bbox'][3] / heigth,\n",
    "                                mean_heigth, mean_width]\n",
    "                line_features += add_reg_features(line_info['text'])\n",
    "                line_features += mean_color(line_info['bbox'], img)\n",
    "                doc_features.append(line_features)\n",
    "            features.append(doc_features)\n",
    "        return features\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prev_next_features(doc, line_features, num_line):\n",
    "    \"\"\"\n",
    "    doc - list of line_features\n",
    "    line_features - list of features\n",
    "    \"\"\"\n",
    "    add_f = [0] * len(line_features)\n",
    "    extended_doc = [add_f] * 4 + doc + [add_f] * 4\n",
    "    return reduce(lambda x, y: x + y, extended_doc[num_line: num_line + 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddPrevNextFeatures:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X - list of doc_features\n",
    "        doc_features - list of line_features\n",
    "        \n",
    "        for each line 4 previous and 4 next features added\n",
    "        result list of lines features\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        for doc_features in X:\n",
    "            i = 0\n",
    "            for line_features in doc_features:\n",
    "                new_features = add_prev_next_features(doc_features, line_features, i)\n",
    "                i += 1\n",
    "                result.append(new_features)\n",
    "        return np.array(result)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://neurohive.io/ru/osnovy-data-science/gradientyj-busting/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xgboost.readthedocs.io/en/latest/tutorials/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2num(string):\n",
    "    if string == \"text\":\n",
    "        return 3\n",
    "    if string == \"other\":\n",
    "        return 4\n",
    "    if string == \"list\":\n",
    "        return 2\n",
    "    return 1\n",
    "\n",
    "with open(\"data.json\", \"r\") as read_file:\n",
    "    docs = json.load(read_file)\n",
    "    y = []\n",
    "    for doc in docs:\n",
    "        elem = [str2num(line['label']) for line in doc['entities']]\n",
    "        y.append(elem)\n",
    "    X = []\n",
    "    for doc in docs:\n",
    "        elem = {}\n",
    "        elem['name'] = doc['name']\n",
    "        elem['entities'] = [{'text': line_info['text'], \n",
    "                        'bbox': [line_info['x'], line_info['y'],\n",
    "                                line_info['width'], line_info['height']]}\n",
    "                      for line_info in doc['entities']]\n",
    "        X.append(elem)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7752960550486914, 0.8051448758674601, 0.7886090243312409]\n",
      "0.7896833184157975\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(AddImgFeatures(),\n",
    "                    AddPrevNextFeatures(),\n",
    "                    GradientBoostingClassifier())\n",
    "\n",
    "scores = []\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train = reduce(lambda x1, x2: x1 + x2, y[train_index])\n",
    "    y_test = reduce(lambda x1, x2: x1 + x2, y[test_index])\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting 3 folds 0.7896833184157975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8192133684222185, 0.7794326745590715]\n",
      "0.799323021490645\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = make_pipeline(AddImgFeatures(),\n",
    "                    AddPrevNextFeatures(),\n",
    "                    XGBClassifier())\n",
    "\n",
    "scores = []\n",
    "\n",
    "kf = KFold(n_splits=2)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train = np.array(reduce(lambda x1, x2: x1 + x2, y[train_index]))\n",
    "    y_test = np.array(reduce(lambda x1, x2: x1 + x2, y[test_index]))\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = []\n",
    "\n",
    "# param = {\n",
    "#    'max_depth': 3,\n",
    "#    'eta': 0.3, \n",
    "#    'silent': 1, \n",
    "#    'objective': 'multi:softprob',\n",
    "#    'num_class': 4}\n",
    "# num_round = 20\n",
    "\n",
    "# kf = KFold(n_splits=3)\n",
    "# for train_index, test_index in kf.split(X):\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train = reduce(lambda x1, x2: x1 + x2, y[train_index])\n",
    "#     y_test = reduce(lambda x1, x2: x1 + x2, y[test_index])\n",
    "    \n",
    "#     aif = AddImgFeatures()\n",
    "#     af = AddPrevNextFeatures()\n",
    "    \n",
    "#     X_train = aif.fit_transform(X_train)\n",
    "#     X_train = np.array(af.fit_transform(X_train))   \n",
    "#     X_test = aif.fit_transform(X_test)\n",
    "#     X_test = np.array(af.fit_transform(X_test))\n",
    "    \n",
    "#     dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "#     dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "    \n",
    "#     bst = xgb.train(param, dtrain, num_round)\n",
    "#     preds = bst.predict(dtest)\n",
    "    \n",
    "#     y_pred = np.asarray([np.argmax(line) for line in preds])\n",
    "#     scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "# print(scores)\n",
    "# print(np.mean(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
